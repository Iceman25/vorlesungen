\chapter{Mikroprozessoren II}

Zusammenfassung der Vorlesung "`Mikroprozessoren II"' aus dem Wintersemester 2015.\footnote{\url{https://capp.itec.kit.edu/teaching/mp2/?lang=d&sem=ws15}}

\section{Einführung}

Entwurf einer Rechneranlage: Ingenieurmäßige Aufgabe der Kompromissfindung zwischen:
\begin{itemize}
	\item Zielsetzung: Einsatzgebiet, Anwendungsbereich, Leistung, Verfügbarkeit, etc.
	\item Randbedingungen: Technologie, Größe, Geld, Energieverbrauch Umwelt, etc.
	\item Gestaltungsgrundsätze: Modularität, Sparsamkeit, Fehlertoleranz, etc.
	\item Anforderungen: Kompatibilität, Betriebssystemanforderungen, Standards, etc.
\end{itemize}


\subsection{Entwurfsfragen: Zielsetzungen}

\subsubsection{Einsatzgebiete}
\begin{itemize}
	\item \textbf{Desktop Computing}
	\begin{itemize}
		\item PCs bis Workstations (\$1000 - \$10.000)
		\item Günstiges Preis-/Leistungsverhältnis
		\item Ausgewogene Rechenleistung für ein breites Spektrum von (interaktiven) Anwendungen
	\end{itemize}
	\item \textbf{Server}
	\begin{itemize}
		\item Rechen- und datenintensive Anwendungen
		\item Hohe Anforderungen an die Verfügbarkeit und Zuverlässigkeit
		\item Skalierbarkeit
		\item Große Dateisysteme und Ein-/Ausgabesysteme
	\end{itemize}
	\item \textbf{Eingebettete Systeme}
	\begin{itemize}
		\item Mikroprozessorsysteme, eingebettet in Geräte und daher nicht unbedingt sichtbar
		\item Sind auf spezielle Aufgaben zugeschnitten (hohe Leistungsfähigkeit, Spezialprozessoren)
		\item Breites Preis-/Leistungsspektrum
		\item Echtzeitanforderungen
		\item Abwägung der Anforderungen an Rechenleistung, Speicherbedarf, Kosten, Energieverbrauch, etc.
	\end{itemize}
\end{itemize}

\subsubsection{Anwendungsbereiche}
\begin{itemize}
	\item Technisch-wissenschaftlicher Bereich: Hohe Anforderungen an die Rechenleistung, insbesondere Gleitkommaverarbeitung
	\item Kommerzieller Bereich: Datenbanken, WEB, Suchmaschinen, Optimierung von Geschäftsprozessen, etc.
	\item Eingebettete Systeme: Verarbeitung digitaler Medien, Automatisierung, Telekommunikation, etc.
\end{itemize}

\subsubsection{Rechenleistung}
\begin{itemize}
	\item Ermittlung übr Benchmarks
	\item Maßzahlen für die Operationsleistung: \textit{MIPS} oder \textit{MFLOPS}
	\item \(MFLOPS = \frac{Anzahl~ausgefuehrter~Gleitkommainstruktionen}{10^6 \cdot Ausfuerhungszeit}\)
\end{itemize}

\subsubsection{Zuverlässigkeit}
\begin{itemize}
	\item Bei Ausfällen von Komponenten muss ein betriebsfähiger Kern bereit sein
	\item Verwendung redundanter Komponenten
	\item Bewertung der Ausfallwahrscheinlichkeit mittels stochastischer Verfahren
	\item Definition Verfügbarkeit: Wahrscheinlichkeit, ein System zu einem beliebigen Zeitpunkt fehlerfrei anzutreffen
\end{itemize}

\subsubsection{Energieverbrauch, Leistungsaufname}
\begin{itemize}
	\item \textbf{Mobile Geräte}
	\begin{itemize}
		\item Verfügbare Energiemenge durch Batterien und Akkumulatoren ist begrenzt \(\rightarrow\) möglichst lange mit der vorhandenen Energie auskommen
		\item Vermeiden von Überhitzungen
	\end{itemize}
	\item Green IT: Niedriger Energieverbrauch, ökologische Produktion, einfaches Recycling
\end{itemize}

\subsubsection{Trends in der Rechnerarchitektur: Herausforderungen}
Weltweite Forschungsaktivitäten bzgl. ExaScale-Rechner
\begin{itemize}
	\item Verlustleistung: Überträgt man heutige (Stand 2010) Höchstleistungsrechner in den Exascale-Bereich, hätte man eine Verlustleistung von etwa 40 GW (diese kann allerdings höchstens 20-40 MW betragen)
	\item Hauptspeicher (DRAM), permanenter Speicher: Kapazität und Zugriffsgeschwindigkeit muss mit der Rechengeschwindigkeit mithalten
	\item Zuverlässigkeit und Verfügbarkeit
	\item Parallelität und Lokalität
\end{itemize}


\subsection{Entwicklung der Rechnertechnik}

\subsubsection{Halbleitertechnologie}
\begin{itemize}
	\item Mikrominiaturisierung setzt sich fort. Verkleinerung der Strukturbreiten sowie Erhöhung der Integrationsdichte: Anzahl der Transistoren verdoppelt sich alle 18 Monate)
	\item \textbf{Technologische Entwicklung bei Intel Prozessoren}
	\begin{itemize}
		\item Neuer Herstellungsprozess alle zwei Jahre mit Verdopplung der Transistorenanzahl
		\item Strukturgröße reduziert sich jedes Jahr um 30\% oder halbiwert sich alle 5 Jahre
		\item 1 Mrd. Transistoren in 2018 \(\rightarrow\) 100 Mrd. in 2021
	\end{itemize}
\end{itemize}

\subsubsection{Forschungsansätze}
\begin{itemize}
	\item Erforschung zukünftiger Fertigungstechnologien auf der Grundlage von Kohlenstoff, Nanotechnologie
	\item Beispiele: Single Molecule Diode, Single Electron Transistor, Carbon Nano Tube
\end{itemize}


\subsection{Entwicklung der Mikroprozessortechnik}

\subsubsection{Taktrate}
\begin{itemize}
	\item Bis 2000 ist die Taktrate exponentiell gestiegen
	\item Steigerung der Prozessorleistung seither durch Verbesserungen des Herstellungsprozesses, tieferen Pipelines und verbesserten Schaltkreistechnologien
\end{itemize}

\subsubsection{Steigerung der Rechenleistung durch Parallelverarbeitung}
\begin{itemize}
	\item Integration vieler Prozessorkerne auf einem Chip (Multicore/Manycore)
	\item Integration hierarchischer Speicher-/Cache-Strukturen
	\item Neue Verbindungsstrukturen (beispielsweise NoCs)
	\item Adaptive Strukturen
\end{itemize}

\subsubsection{Aufbau eines Rechners mit Multicore}
\begin{itemize}
	\item \textbf{Aufbau eines Rechners mit Multicore}
	\begin{itemize}
		\item Mehrere Prozessorkerne mit separaten Steuerwerk und Rechenwerk, teilweise auch eigener Cache (L1 und L2)
		\item Gemeinsamer Shared Cache (L3)
		\item Northbridge zur Anbindung schneller Geräte (PCIe, RAM) und Sothbridge für die restlichen Geräte (IDE, SATA, PCI, SMB, HD-Audio, etc.)
		\item Struktur: \texttt{CPU<-----Front Side Bus----->Northbridge<-----Direct Media Interface----->Southbridge}
	\end{itemize}
	\item \textbf{Speicher-/Cache-Strukturen}
	\begin{itemize}
		\item Zugriffsgeschwindigkeit der Hauptspeicherkomponenten (DRAMs) wächst nicht mit der Prozessorgeschwindigkeit: Lücke zwischen Zugriffsgeschwindkeit und Prozessorgeschwindigkeit (Memory Wall) \(\rightarrow\) Lösung: Speicherhierarchie
		\item Zuwachs Prozessorgeschwindkeit pro Jahr um 50\% gegenüber Steigerung der Zugriffsgeschwindigkeit um 7\% pro Jahr
	\end{itemize}
	\item \textbf{Verbinungsstrukturen}
	\begin{itemize}
		\item Hierarchische Mehrbusstrukturen
		\begin{itemize}
			\item Verbinden Komponenten auf verschiedenen Ebenen
			\item On-Chip Verbindungsnetzwerke: Leiten Werte zwischen den Pipelinestufen weiter und verbinden Prozessorkerne
			\item Systemverbindungsstrukturen: Verbinden Prozessoren (CMPs) mit Speicher und I/O
			\item Peripheriebusse: Verbinden I/O-Schnittstellenbausteine mit dem Systembus
			\item System-Verbindungsnetzwerke: SANs (sehr kurze Entfernungen), LANs (in Organisationen und Gebäude) und WANs (weite Entfernungen)
		\end{itemize}
		\item Punkt-zu-Punkt-Verbindungen: Quick-Path-Interconnect (QPI)
		\begin{itemize}
			\item Von Intel entwickelte Struktur zur Kommunikation zwischen Prozessoren untereinander und für die Kommunikation zwischen Prozessoren und Chipsatz
			\item Direkte Verbindungen können zwischen jedem Prozessorpaar eingerichtet werden
			\item Anbindung von PCIe und dediziertem Speicherbus
		\end{itemize}
	\end{itemize}
\end{itemize}



\section{Parallelismus auf Maschinenbefehlsebene}

\subsection{Einführung}

\subsubsection{RISC (Reduced Instruction Set Computers)}
Einfache, einzyklische Maschinenbefehle; Load/Store Architektur; optimierende Compiler.

\subsubsection{Pipelining (Instruction Pipelining)}
\begin{itemize}
	\item Zerlegung der Ausführung einer Maschinenoperation in Teilphasen, die dann von hintereinander geschalteten Verarbeitungseinheiten taktsynchron ausgeführt werden, wobei jede Einheit genau eine spezielle Teiloperation ausführt.
	\item Stufen einer Standard-RISC-Pipeline (DLX-Pipeline: \texttt{Instruction Fetch (IF)}, \texttt{Instruction Decode (ID)}, \texttt{Execution (EX)}, \texttt{Memory Access (MA)} und \texttt{Writeback (WB)}, wobei alle Stufen unterschiedliche Ressourcen benutzen
	\item Idealerweise wird mit jedem Takt ein Befehl beendet
	\item Zykluszeit abhängig von der langsamsten Pipelinestufe
	\item Gleitkommeverarbeitung und Integer-Division: Einführung spezieller Rechenwerke, um die Berechnung innerhalb eines Schrittes ausführen zu können
	\item \textbf{Verfeinerung der Pipeline-Stufen ("`Superpipelining"')}
	\begin{itemize}
		\item Weitere Unterteilung der Pipeline-Stufen
		\item Weniger Logik-Ebenen pro Pipeline-Stufe % TODO
		\item Erhöhung der Taktrate
		\item Führt aber auch zu einer Erhöhung der Ausführungszeit pro Instruktion
	\end{itemize}
\end{itemize}

\subsubsection{Superskalar}
\begin{itemize}
	\item Mehrfachzuweisung: Pro Takt können mehrere Befehle den Ausführungseinheiten zugeordnet und die gleiche Anzahl von Befehlsausführungen pro Takt beendet werden
	\item RISC-Eigenschaften bleiben weitestgehend erhalten
	\item Entwurfsziel: Erhöhung des IPC (Instruction per Cycle)
\end{itemize}

\subsubsection{Datenabhängigkeiten und Konflikte}
\begin{itemize}
	\item Situationen, die verhindern, dass die nächste Instruktion im Befehlsstrom im zugewiesenen Taktzyklus ausgeführt wird
	\item Verursachen Leistungseinbußen und erfordern ein Anhalten der Pipeline ("`Leerlaufen"' lassen der Pipeline)
	\item \textbf{Strukturkonflikte}
	\begin{itemize}
		\item Ergeben sich aus Ressourcenkonflikten: Die Hardware kann nicht alle möglichen Kombinationen von Befehlen unterstützen, die sich in der Pipeline befinden
		\item Beispiel: Gleichzeitiger Schreibzugriff zweier Befehle auf einer Registerdatei mit nur einem Schreibeingang
	\end{itemize}
	\item \textbf{Datenkonflikte}
	\begin{itemize}
		\item Ergeben sich aus Datenabhängigkeiten zwischen Befehlen im Programm (und sind damit Eigenschaften des Programms)
		\item Instruktion benötigt das Ergebnis einer vorangehenden und noch nicht abgeschlossenen Instruktion in der Pipeline
		\item Verschiedene Datenkonflikte\footnote{\url{https://de.wikipedia.org/wiki/Pipeline-Hazard}}
		\begin{itemize}
			\item Echte Datenabhängigkeiten (Read-after-Write): Ein Operand wurde verändert und kurz darauf gelesen. Da der erste Befehl den Operanden evtl. noch nicht fertiggeschrieben hat (Pipeline-Stufe "`store"' ist weit hinten), würde der zweite Befehl falsche Daten verwenden. Ein "`Shortcut"' im Datenweg der Pipeline kann den Hazard vermeiden. Bei problematischeren Situationen, wenn beispielsweise ein Rechenergebnis zur Adressierung verwendet wird oder bei berechneten und bedingten Sprüngen, ist ein Anhalten der Pipeline aber unumgänglich.
			\item Gegenabhängigkeit (Write-after-Read): Ein Operand wird gelesen und kurz danach überschrieben. Da das Schreiben bereits vor dem Lesen vollendet sein könnte, könnte der Lese-Befehl die neu geschriebenen Werte erhalten. In der normalen Pipeline eher kein Problem.
			\item Ausgabeabhängigkeit (Write-after-Write): Zwei Befehle schreiben auf denselben Operanden. Der zweite könnte vor dem ersten Befehl beendet werden und somit den Operanden mit einem falschen Wert belassen.
		\end{itemize}
	\end{itemize}
	\item \textbf{Steuerkonflikte}
	\begin{itemize}
		\item Treten bei Verzweigungsbefehlen und anderen Instruktionen auf, die den Befehlszähler verändern
	\end{itemize}
\end{itemize}


\subsection{Superskalartechnik}

\subsubsection{Superskalare Prozessorpipeline}
\begin{itemize}
	\item \textbf{1. In-order-Abschnitt}
	\begin{itemize}
		\item Befehle werden entsprechend ihrer Programmordnung bearbeitet
		\item Umfasst: Befehlsholphase (IF), Dekodierphase (ID) und Dispatch
		\item Dynamische Zuordnung der Befehle an die Ausführungseinheiten. Der Scheduler bestimmt die Anzahl der Befehle, die im nächsten Takt zugeordnet werden können
		\item Befehlsholphae (IF)
		\begin{itemize}
			\item Holen mehrerer Befehle aus dem Befehlscache in der Befehlsholpuffer (Anzahl entspricht typischerweise der Zuordnungsbreite)
			\item Welche Befehle geholt werden hängt von der Sprungvorhersage ab
		\end{itemize}
		\item Verzweigungseinheit
		\begin{itemize}
			\item Überwacht die Ausführung von prungbefehlen
			\item Spekulatives Holen von Befehlen und Spekulation über den weiteren Programmverlauf (Verwendung hierzu der Vorgeschichte)
			\item Gewährleistet im Falle einer Fehlspekulation die Abänderung der Tabellen sowie das Rückholen der fälschlicherweise ausgeführten Befehle
		\end{itemize}
		\item Befehlsholpuffer: Entkoppelt die IF-Phase von der ID-Phase
	\end{itemize}
	\item \textbf{Out-of-order-Abschnitt}
	\begin{itemize}
		\item Ausführungsphase
	\end{itemize}
	\item \textbf{2. In-order-Phase}
	\begin{itemize}
		\item Gültigmachen der Ergebnisse entsprechend der ursprünglichen Programmordnung
		\item Einhalten der korrekten Programmsemantik (Ausnahmeverarbeitung, Spekulation)
	\end{itemize}
\end{itemize}

\subsubsection{Spekulative Ausführung}
\begin{itemize}
	\item Befehlsausführung über nicht aufgelöste Verzweigungen. Impliziert, dass ein Befehl nutzlos sein kann, da zum Ausführungszeitpunkt nicht bekannt ist, ob der Befehl ausgeführt werden soll
	\item Mikroarchitektur muss die Ressourcen haben und in der Lage sein, die Effekte einer fälschlicherweise spekulativ ausgeführten Instruktion zu löschen (beispielsweise Modifikationen im Speicher oder bei Ausnahmesituationen)
	\item \textbf{Sprungvorhersage (Branch Prediction)}
	\begin{itemize}
		\item Verhalten beim Auftreten von Verzweigungen: Vorhersagen des Sprungziels; Füllen der Verzögerungsphasen spekulativ mit Befehlen; Fortfahren mit der Ausführung ohne Verzögerung bei korrekter Vorhersage oder Verwerfen der geholten Befehle bei falscher Vorhersage
		\item Ansätze
		\begin{itemize}
			\item Statische Sprungvorhersage: Richtung der Vorhersage ist für einen Befehl immer gleich und festverdrahtet. Sprungvorhersage durch den Compiler
			\item Dynamische Sprungvorhersage
			\begin{itemize}
				\item Hängt von der Vorgeschichte ab und berücksichtigt das Programmverhalten
				\item Genauere Vorhersagen bei allerdings auch höherem Hardwareaufwand möglich
				\item Sprungzielcache: \texttt{Branch Target Address Cache} (Tabelle: Adresse der Verzweigung \(\rightarrow\) Sprungzieladresse) und \texttt{Branch Target Buffer} (Direct-mapped-Cache) speichern die Adresse der Verzweigung und das entsprechende Sprungziel
				\item \texttt{Branch History Table} hält das Verhalten der Sprungbefehle während der Ausführung des Programms fest: Prädikatoren
			\end{itemize}
		\end{itemize}
	\end{itemize}
\end{itemize}


\subsection{Very Long Instruction Word (VLIW)}


\subsection{Explicitly Parallel Instruction Computing (EPIC)}



\section{Parallelismus auf Thread-Ebene}



\section{Multicore/Manycore}



\section{Systemstrukturen}
