\section{Appendix A: Algorithmen und Erklärungen}

Aufstellung und Erläuterung aller Algorithmen der Vorlesung Vorlesung "`Algorithmen II"' aus dem Wintersemester 2014.\footnote{\url{http://geom.ivd.kit.edu/ws14_algo2.php}}

\subsection{Algorithmus von Ford und Fulkerson}

\begin{algorithm}[H]
	\caption{Ford-Fulkerson}
	\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
	\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}

	\Input{$F(G,k,q,s)$}
	\Output{Ein maximaler Fluß $f$}
	\BlankLine

	$f \longleftarrow 0$

	\While{Es gibt einen Pfad $q \rightarrow^* s$ in $G_f$} {
		Erhöhe $f$ über diesem maximal
	}
\end{algorithm}

\subsubsection{Korrektheit}
\begin{itemize}
	\item Terminiert sicher für alle rationalen Eingaben\footnote{\url{http://de.wikipedia.org/wiki/Algorithmus_von_Ford_und_Fulkerson\#Zur_Korrektheit_des_Algorithmus}}
	\item Terminiert, da \(W_f\) immer um mindestens \(1\) erhöht wird und \(W_f \leq \sum k(q,V) < \infty\)
	\item Irrationale Kapazitäten: Terminiert nicht, da der Algorithmus unendliche lange laufen kann oder ein falsches Ergebnis liefert
\end{itemize}

\subsubsection{Laufzeit}
\begin{itemize}
	\item \(\mathcal{O}(|E|~max\{W_f~|~Fluss~in~F\})\), denn ein Pfad \(q \rightarrow^* s\) in \(|E|\) gefunden werden kann.
	\item Die Laufzeit hängt stark von der Anzahl der Schleifendurchläufe ab, da flussvergrößernde Pfade sehr ungünstig gewählt werden können.
\end{itemize}


\subsection{Algorithmus von Edmonds und Karp}
Erhöht man den Fluß in Ford-Fulkerson imer längs eines kürzesten Pfads (Breitensuche), erhält man den Edmonds-Karp-Algorithmus.

\begin{itemize}
	\item Die Länge \(l_f x\) der kürzesten Pfade \(q \rightarrow^* s\) in \(G_f\) wächst monoton
	\item Terminiert für reelle Eingaben
\end{itemize}

\subsubsection{Laufzeit}
\begin{itemize}
	\item Anzahl der Iterationen \(\in \mathcal{O}(|E| \cdot |V|)\), da \(E_f\) in jedem Schritt eine Kante verliert, die später eventuell als Gegenkante genutzt wird.
	\item Dadurch wächst der Fluss um mindestens \(2\)
	\item Da \(l_f y < |V|-1\) verliert \(E_f\) eine Kante maximal \(\frac{|V|}{2}\) Mal (\(\rightarrow\) Anzahl der Iterationen)
	\item Durch die Breitensuche ergibt sich eine Gesamtlaufzeit von \(\mathcal{O}(|E|^2 \cdot |V|)\)
\end{itemize}


\subsection{Die Präfluss-Pusch-Methode}
Jeder Knoten erhält zusätzlich eine Höhe und ein Reservoir, um vorübergehend beliebig viel Fluss speichern zu können. Diese könnten nur bergab entleert werdern.

\subsubsection{Push}
\(Push(x,y)\) ist nur erlaubt, wenn Überschuss bei \(x\) vorhanden und \(h(x)-h(y) \geq 1\) ist.

\begin{algorithm}[H]
	\caption{Push}
	\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
	\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}

	\Input{$x,y$}
	\Output{}
	\BlankLine

	$d \longleftarrow \min{ü(x), k_f(x,y)}$ \newline
	$f(x,y) \longleftarrow f(x,y) +d$ \newline
	$ü(x) \longleftarrow ü(x) -d $ \newline
	$ü(y) \longleftarrow ü(y) +d$ \newline
\end{algorithm}

\subsubsection{Lifte}
\(Lifte(x)\) ist nur erlaubt, wenn Überschuss bei \(x\) vorhanden und \(h(x) \leq \min_{(x,y) \in E_f}{h(y)}\) ist.

\begin{algorithm}[H]
	\caption{Lifte}
	\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
	\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}

	\Input{$x$}
	\BlankLine

	$h(x) := 1+ \min_{(x,y) \in E_f}{h(y}$
\end{algorithm} 


\begin{algorithm}[H]
	\caption{Präfluss-Pusch}
	\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
	\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}

	\Input{$F(G,k,q,s$}
	\Output{Maximaler Fluss $f$}
	\BlankLine

	\For{alle $ x,y \in V $ }{
	$ h(x)  \leftarrow \begin{cases}|V| & x=q \\ 0 & \text{sonst}\end{cases}$ \newline
	$ f(x,y)  \leftarrow \begin{cases}k(x,y) & x=q \\ 0 & \text{sonst}\end{cases}$}
	\While{Es gibt erlaubte Push oder Lifte Operationen} {Führe beliebig Push oder Lifte aus}
\end{algorithm}

\subsubsection{Korrektheit}
\begin{itemize}
	\item Im Verlauf des Algorithmus bleibt \(h\) immer eine gültige Höhenfunktion, da alle erlaubten Operationen die Grundbedingungen des Flussnetzwerks nicht verletzen.
	\item Terminiert der Algorithmus, ist \(f\) maximal, da es keinen weiteren Pfad \(q \rightarrow^* s\) gibt (da ansonten gelten müsste: \(h(s) \geq h(q)-|V|+1=1\))
\end{itemize}

\subsubsection{Laufzeit}
\begin{itemize}
	\item Anzahl durchgeführter Lifte- und Pusch-Operationen \(\in \mathcal{O}(|V|^2 \cdot |E|)\)
	\item Daher kann der Algorithmus auch mit dieser Laufzeit implementiert werden
\end{itemize}


\subsection{"`An die Spitze"' Präfluss-Pusch-Algorithmus}
Formalisierung bzw. Erweiterung des \textit{Präfluss-Pusch-Algorithmus}.
\begin{itemize}
	\item Verwaltung einer Knotenliste \(L\) in der \(x\) vor \(y\) auftritt, falls \((x,y)\) puschbar ist
	\item Verwaltung einer Nachbarknotenliste pro Knoten
\end{itemize}

\begin{algorithm}[H]
	\caption{Leere}
	\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
	\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}

	\Input{$x$}
	\BlankLine

	\While{$u(x)>0$}{	
		\If{$i_x > 0$}{
			$y \longleftarrow n_x(i_x)$ \newline
			\If{$(x,y)~puschbar$}{
				$Pusch(x,y)$}
			\Else{
				$i_x \longleftarrow i_x -1$}
			}
		\Else{	$Lifte(x)$ \newline
				$i_x \longleftarrow Grad(x)$}
			
		}	
\end{algorithm}

\begin{algorithm}[H]
	\caption{An die Spitze}
	\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
	\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}

	\Input{$F(G,k,q,s)$}
	\Output{Ein maximaler Fluss $f$}
	\BlankLine
	
	Initialisiere $f$ und $h$ wie in Präfluss-Pusch \newline
	Generiere $L$ \newline
	$x \longleftarrow Kopf(L)$
	\BlankLine

	\For{$x \in V$}{
		$i_x \longleftarrow Grad(x)$}
	\BlankLine

	\While{$x \ne Nil$ }{	
		$h_{alt} \longleftarrow h(x)$ \newline
		$Leere(x)$ \newline
		\If{$h_{alt} < h(x)$}{
			Setze $x$ an die Spitze von $L$
		}
		\BlankLine
		$x \longleftarrow \text{Nachfolger von x in L}$
	}
\end{algorithm}

\subsubsection{Laufzeit}
Faktoren, welche die Laufzeit beeinflussen:
\begin{itemize}
	\item Anzahl Aufrufe von \(Leere(x)\) mit \(u(x) = 0\)
	\item Anzahl der Aufrufe der Hauptschleife
\end{itemize}
Laufzeit damit \(\in \mathcal{O}(|V|^3)\).

\subsection{Paaren in allgemeinen Graphen}
\begin{algorithm}[H]
	\caption{Paare}
	\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
	\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}

	\Input{bipartiter Graph $(V_1 \stackrel{\cdot}{\cup} V_2, E)$}
	\Output{Maximale Paarung P}
	\BlankLine
	
	$V \longleftarrow V_1 \cup V_2 \cup \{ q,s \}$ \newline
	$\hat{E} \longleftarrow \{ q \} \times V_1 \cup E \cup V_2 \times \{ s \} $ \newline
	$k \longleftarrow \begin{cases}1 & e \in \hat{E} \\ 0 & \text{sonst}\end{cases}$ \newline
	$f \longleftarrow Ford-Fulkerson( F(V, \hat{E} ),h,q,s)) $ \newline
	$P \longleftarrow \{ e \in E | f(e) = 1 \} $
\end{algorithm}


\subsection{Sortieren durch stochastisches Teilen}
\begin{algorithm}[H]
	\caption{Quicksort}
	\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
	\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}

	\Input{$ S : = \{ s_1, ... , s_n \} $ 	mit paarweise verschiedenen 	$ s_i \in \mathbb{Z} $ 	}
	\Output{$( \delta_1, ... , \delta_n)$ mit $\delta_1 < ... < \delta_n$ und $\{ \delta_1, ... , \delta_n \} = S $}
	\BlankLine
	
	\While{ S $\ne \emptyset$} {
		Wähle ein zufälliges Pivotelement $ y \in S $ \newline
		Zerlege $S \setminus \{ y \} $ 	in 	$  s_1 $ und $ s_2 $ , so dass 	$ s_1 < y < s_2 $ \newline
		Gib $ ( Quicksort(s_1 , y ),Quicksort(s_2))$ aus \newline
		}
\end{algorithm}

\subsection{Minimaler Schnitt}
\begin{algorithm}[H]
	\caption{Schnitt}
	\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
	\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}

	\Input{$ (V,E) $ ein ungerichteter Multigraph}
	\Output{Ein Schnitt S}
	\BlankLine
	
	\While{ $|V| \ge 3$} {
		Wähle ein zufälliges Kante $ (x,y) \ in E $ \newline
		Entferne Alle $(x,y)$ aus $E$ \newline
		Verschmelte x mit y \newline
		}
	Gib $S:=E$ aus
\end{algorithm}

\begin{algorithm}[H]
	\caption{Finde}
	\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
	\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}

	\Input{$S:= \{ s_1 , ... , s_n \} \subset \mathbb{M}$}
	\Output{$ \delta_k$, wobei $\delta_1, ... , \delta_n \in S$ und $\delta_1 < ... < \delta_n$}
	\BlankLine
	
	Wähle y zufällig aus $S$\newline
	$S_1 \longleftarrow \{ x \in S | x < y \} $\newline
	$S_2 \longleftarrow \{ x \in S | x > y \} $ \newline
	\If{ $|S_1| = k-1$}{ gib y aus}
	\Else{
		\If{$|S_1| > k-1$}{$Finde(S_1,k)$}
		\Else{$Finde(S_2, k-|S_1|-1)$}
		}
\end{algorithm}

\subsection{Spielbaumauswertung}
\begin{algorithm}[H]
	\caption{Wert}
	\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
	\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}

	\Input{x Knoten eines binären Spielbaums}
	\Output{$Wert(x)$}
	\BlankLine
	
	Wähle y zufällig aus S \newline
	$(y,z) \longleftarrow $ Paare der Kinder von x in zufälliger Reihenfolge\newline
	$W \longleftarrow Wert(y)$ \newline
	\If{ $w=1$}{gib 0 aus}
	\Else{
		gib 0 XOR Wert(z) aus}
\end{algorithm}

\subsection{Eckentausch - Lineares Programm}
Um $z$ zu maximieren, machen wir sukzessiv neue $y_i$ zu neuen Koordinaten, so das der Ursprung von Ecke zu Ece von S wandert und der Wert von z im Ursprung wächst. Dazu tauschen wir immer eine Koordinate von $\bar{y}$ mit einer von $\overline{\bar{y}}$ .

\begin{algorithm}[H]
	\caption{Austausch}
	\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
	\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}

	\Input{Matrix A, r, s}
	\Output{Matrix A'}
	\BlankLine
	
	\For{$i \neq r AND j \neq s$}{
		$a'_{ij} \longleftarrow a_{ij} - \frac{a_{is}a_{rj}}{a_{rs}}$
		}
		
	\tcc{Pivotzeile}
	\For{$i=r AND j \neq s$ }{
		$a'_{ij} \longleftarrow - \frac{a_{ij}}{a_{rs}}$
		}
	\tcc{Pivotspalte}
	\For{$i \neq r AND j=s$}{
		$a'_{ij} \longleftarrow \frac{a_{ij}}{a_{rs}} $
		}
	\tcc{Pivot}
	\For{$i=r AND j=s$}{
		$a'_{ij} \longleftarrow \frac{1}{a_{rs}} $
		}
\end{algorithm}

\begin{algorithm}[H]
	\caption{Simplex}
	\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
	\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}

	\Input{Normalform eines linearen Programms}
	\Output{Geänderte Normalform so dass $z(0) =  c = max$}
	\BlankLine
	
	\While{$\exists c_s > 0$}{
		\If{$\forall b_{is} \geq 0 $}{
			keine Lösung - Ende
			}
		\Else{
			bestimme r, so dass $\frac{b_r}{b_{rs}} = \max_{b_{is} 0} \frac{b_i}{b_{is}}$
			}
	$B \longleftarrow Austausch(B,r,s)$
	}
\end{algorithm}

\subsection{Binäre Zerlegung des Raum}
Rekursive Zerlegung eines Polyeders des \(\mathbb{R}^3\) anhand einiger Polygone. Pro Iterationsschritt wird jeweils ein Polygon bestimmt (bevorzugt eines, das den Polyeder komplett zerlegt). Dieses teilt den Polyeder in einen linken und einen rechten Teilpolyeder, die jeweils weiter zerlegt werden.

\begin{algorithm}[H]
	\caption{BRZ}
	\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
	\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}

	\Input{Ein Polyeder $P \subset \mathbb{R}^3$; orientierte, planare, disjunkte Polygone $P_1,...,P_n \subset \mathbb{R}^3$}
	\Output{Ein $RBZ$ für $P_1,...,P_n$}
	\BlankLine

	$k \longleftarrow 1$
	\BlankLine
	\tcc{Sortiere Polygonenteile aus, die außerhalb von $P$ liegen (Clipping)}
	\For {$i=1,...,n$}{
		$Q_k \longleftarrow P_1 \cap P$
		\If {$Q_k \neq \emptyset$} {
			$k \longleftarrow k + 1$
		}
	}

	$l \longleftarrow 1$

	\BlankLine
	\tcc{Falls ein Polygon $P$ komplett zerteilt, nehme dieses als Trennelement. Anderenfalls nehme das erste in der Liste}
	\If{Exists $j$: $Q_j$ zerlegt P vollständig}{
		$l \longleftarrow j$
	}

	$Wurzel \longleftarrow Q_l$
	\BlankLine
	\tcc{Teile $P$}
	\If{$k \geq 3$}{
		$Q \longleftarrow P \cap li.~HR~von~Q_l$\newline
		$li. Wurzelteilbaum \longleftarrow BRZ(Q,Q_1,...,Q_{k-1})$\newline
		$Q \longleftarrow P \cap re.~HR~von~Q_l$\newline
		$re. Wurzelteilbaum \longleftarrow BRZ(Q,Q_1,...,Q_{k-1})$
	}

	\BlankLine
	\Return{Wurzel mit ihren Teilbaeumen}

\end{algorithm}


\subsection{Konstruktion konvexer Hüllen}
Die konvexe Hülle einer Teilmenge ist die kleinste konvexe Menge, die die Ausgangsmenge enthält.\footnote{\url{http://de.wikipedia.org/wiki/Konvexe_Hülle}}

\subsubsection{Annahmen}
\begin{itemize}
	\item Die Reiehenfolge der \(p_i\) sei gleichverteilt zufällig
	\item Keine vier der Ebenen \(p_i^{*}\) schneiden sich in einem Punkt
	\item Jeder Knoten hat den Grad \(3\)
\end{itemize}

\begin{algorithm}[H]
	\caption{BRZ}
	\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
	\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}

	\Input{Punktmenge $P=(p_1,..,p_n) \cap A^3$}
	\Output{$\lbrack P \rbrack$}
	\BlankLine

	\tcc{Verschiebe $P$, so dass der Ursprung innerhalb der Konvexen Hülle liegt}
	$v \longleftarrow 0 - \sum_i \frac{p_i}{n}$\newline
	$P \longleftarrow P + v$
	\BlankLine

	\tcc{Schritt 2}
	$V \longleftarrow$ Knotenliste von $p_1^{\leq} \cap ... \cap p_4^{\leq}$\newline
	\For{$j > i$} {
		\eIf{$p_j^{\leq} \supset V$}{
			Entferne $p_j$ aus $P$\newline
			Aktualisiere "`gedanklich"' alle Indizes $k>j$
		}{
			Verknüpfe $p_j$ bidirektional mit einem $w_j \in V_4 \backslash p_j^{\leq}$
		}
	}
	\BlankLine

	\tcc{Schritt 3}
	\For{i = 5,...,n}{
		Durchlaufe $V$ von $w_i$ aus und setze dabei:\newline
			$N_i \longleftarrow \{ Schnittpunkte~der~Kanten~mit~p_i^{*}\}$\newline
			$W_i \longleftarrow V \cap p_i^{>}$\newline
			$V \longleftarrow (V \cup N_i) \backslash W_i$\newline
		\BlankLine
		\For{$j>i$ mit $w_j \in W_i$}{
			\eIf{$N_i \subset p_j^{\leq}$}{
				Entferne $P_j$ aus $P$\newline
				Aktualisiere "`gedanklich"' alle Indizes
			}{
				Verknüpfe $p_j$ neu mit einem $w_j \in N_i \cap p_j^{>}$
			}
		}
	}
	\BlankLine

	\Return{Verschobene Polarmenge $Q_P$}

\end{algorithm}


\subsection{Pledge Startegie}
\begin{itemize}
	\item Findet einen Weg aus einem Labyrinth.
	\item Der Roboter kann erkennen, wenn er das Labyrinth verlassen hat.
	\item Bei jeder Drehung wird die Änderung zum Startwinkel \(\phi\) aktualisiert.
\end{itemize}

\begin{algorithm}[H]
	\caption{Pledge Strategie}
	\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
	\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}

	\Input{Labyrinth $L$ und Roboter $R$}
	\Output{Weg aus dem Labyrinth}
	\BlankLine

	$\varphi \leftarrow 0$
	
	\While{$ R \in L $}{	
		gehe vorwärts bis zu einer Wand.\\
		gehe links der Wand entlang bis $ R \not\in L \text{ oder } \varphi = 0 $	
		}
\end{algorithm}


\subsection{Wanze}

Findet einen Ziel in einer Umgebung mit Hindernissen.\\

\begin{algorithm}[H]
	\caption{Wanze}
	\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
	\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}

	\Input{$P_1 , ... , P_n$ disjunkte, einfache geschlossene Polygone.\\
	$ S, Z $ Start und Ziel $\in A^2 \setminus P$.\\
	Roboter $R$ der seine eigene Position $r$ kennt.}
	\Output{Weg von $S$ nach $Z$.}
	\BlankLine
	
	\While{$r \ne Z$}{	
		gehe Richtung $Z$ bis $r = Z$ oder $r \in P$\\	
		\If{$r \ne Z$} {
                    umlaufe $P_i$, suche dabei $q \in argmin || x - z ||_2 , x \in P_i$ \\
                    (die Stelle auf dem umlaufenen Polygon mit minimalem Abstand zu $Z$.)\\
                    gehe zu $q$
		}
    }
\end{algorithm}

\subsection{Geometrische Algorithmen - Türsuche 1}

Roboter steht vor einer langen Wand und sucht die Tür.\\


\begin{algorithm}[H]
	\caption{Türsuche 1}
	\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
	\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}


	$i \leftarrow 1$
	
	\While{Tür noch nicht gefunden}{	
		gehe $i$ Meter der Wand entlang.\\
		gehe i Meter zurück (ändert die Laufrichtung)\\
		$ i \leftarrow i+1$\\
		}
\end{algorithm}

Weglänge: Ist die Tür n + (0,1) Meter vom Ausgangspunkt entfernt, gilt:\\
Weglänge $\ge 2 \cdot 1 + 2 \cdot 2 + ... + 2n +n = O(n^2)$.\\
$\Rightarrow$ Türsuche 1 ist nicht kompetetiv.


\subsection{Geometrische Algorithmen - Türsuche 2}

Roboter steht vor einer langen Wand und sucht die Tür.\\


\begin{algorithm}[H]
	\caption{Türsuche 2}
	\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
	\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}


	$i \leftarrow 1$
	
	\While{Tür noch nicht gefunden}{	
		gehe $i$ Meter der Wand entlang.\\
		gehe i Meter zurück (ändert die Laufrichtung)\\
		$ i \leftarrow 2i$\\
		}
\end{algorithm}

Weglänge: Ist die Tür $2^{n+\delta}$ Meter vom Ausgangspunkt entfernt, gilt:\\
Weglänge $\le 2 \sum\limits_{i=0}^{n+1} 2^i + 2^{n+\delta} \le 2 ^{n+3+\delta} + 2^{n+\delta} \le 9 \cdot 2^{n+\delta}$.\\
$\Rightarrow$ Türsuche 2 ist 9-kompetetiv.


\subsection{Geometrische Algorithmen - Sternsuche}

Roboter steht in der Mitte eines Kreuzes aus Halbgeraden (beginnen in S).\\

\begin{algorithm}[H]
	\caption{Sternsuche}
	\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
	\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
        
        \Input{$S$ Startpunkt, $Z$ Ziel, $m$ Halbgeraden, startend in S}
        $\forall i \in \mathbb{N}_0 : f_i \leftarrow \left(\frac{m}{m-1}\right)^i$

	$i \leftarrow 0$
	
	\While{Z noch nicht gefunden}{	
		gehe $f_i$ Meter auf $H_{i \text{ mod } m}$ entlang.\\
		gehe zurück zu $S$\\
		$ i \leftarrow i+1$\\
		}
\end{algorithm}

$\Rightarrow$ Sternsuche ist kompetetiv mit factor $c = 2m \left(\frac{m}{m-1}\right)^{m-1}+1$



\subsection{Zufallsgesteuerte Optimierung}
Optimierungsaufgaben bestehen aus 
\begin{enumerate}
\item Suchraum $Q$, Teil des Zustandsraumes $Z$
\item Bewertungsfunktion $c: Z \rightarrow \mathbb{R}$, die jedem Zustand $q$ seine Kosten $c(q)$ zuweist.
\item eine FUnktion $l: Z \rightarrow \mathbb{R}$, die für alle $q \in Q$ die Nebenbedingungen charakterisiert.
\end{enumerate}
Gesucht wird ein $q \in Q$ mit minimalen / maximalen Kosten.\\
Eine Optimierungsaufgabe heißt kombinatorischen, wenn $Q$ diskret ist.\\
Nebenbedingungen können vermieden werden, indem man $c$ so umformuliert, dass
$q \not\in Q$ so schlecht bewertet werden, dass sie nicht als Lösung in Frage kommen:
$c'(q) = c(q) + \gamma \cdot l^2(q)$.\\
$q$ ist globales Optimum: $\forall p \in Q | p \ne q: c(q) \le c(p)$\\
$q$ ist lokales Optimum: $\forall p \in Nachbarn(q): c(q) \le c(p)$\\

\subsubsection{Gradientenverfahren}
Zustandsraum $Z \in \mathbb{R}^n$. Jeder Zustand ist ein Punkt $x = [x_1, ... , X_n]^t$.
Ausgehend vom Startpunk $x_0$ wird der Gradient der Kostenfunktion an der aktuellen Stelle berechnet. 
$\Delta c(x_0) = \left[ \diffp{c}{{x_{1}}}, ... , \diffp{c}{{x_{n}}} \right]$\\
Die Nachfolger werden definiert durch $x_{i+1} = x_i + h \cdot \delta c(x_i)$, wobei $h > 0$ wenn c maximiert wird, $h < 0$ wenn c minimiert wird.\\
Der Gradient ist die Richtung des steilsten auf/abstiegs $Rightarrow$ Methode des steilsten Auf/Abstiegs.\\
Gradientenverfahren sind deterministisch.\\
Es kann passieren, dass nur ein lokales Optimum gefunden wird.\\
$\Rightarrow$ Nur anwenden, wenn es keine lokalen Optima/Minima gibt, Ableitung und Straftherme einfach zu berechnen sind.\\

\subsubsection{Suchverfahren}
Ist der Suchraum diskret, definiert man für alle q die Menge der direkten Nachbarn $N(q) \subset Q$ . $\Rightarrow$ man kann $Q$ von einem Anfangszustand aus durchsuchen.\\
Alle nachfolgenden algorithmen sind Suchverfahren.\\

\paragraph{Simuliertes Tempern}
Nicht so toll, trotzdem lernen.

\begin{algorithm}[H]
	\caption{Simuliertes Tempern}
	\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
	\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
        
        \Input{$t_1, ..., t_i$ Temperaturen, absteigend sortiert\\
        $K$ Anzahl der zu berücksichtigenden Nachbarn\\
        $q$ aktueller Startpunkt\\
        $i$ aktueller Temperaturindex}
        \Output{$q$ - die gefundene Lösung}
        
        \For{k = 1, k $\leq$ K, k++}{
        wähle zufällig Nachbarn $p \in N(q)$\\
        \If{$ c(p) > c(q) \text{ oder } exp(\frac{c(p) - c(q)}{t_i}) > Zufallszahl \in [0,1]$}{
            \Return Simuliertes Tempern($[t_1,..,t_n], K, p, i+1$)
            }
        }
        \Return q\\
\end{algorithm}


\paragraph{Schwellwert Algorithmus}
Wähle zufälligen Nachbarn, gilt $c(p) \ge c(q) - \sigma$, fahre fort mit $q = p$.\\
Schwellwert $\sigma$ wird mit der Zeit kleiner.\\
$\Rightarrow$ Besser als Simuliertes Tempern, kann trozdem in lokalem Maxima hängen bleiben.\\


\paragraph{Sintflut Algorithmus}
Starte mit $\sigma = 0$. Wähle zufälligen Nachbarn. Gilt $c(p) > \sigma$, fahre fort mit $q = p$.\\
$\sigma$ wird mit der Zeit größer.\\
$\Rightarrow$ Besser als Simuliertes Tempern, kann trozdem in lokalem Maxima hängen bleiben.\\

\paragraph{Rekordjagt Algorithmus}
Bisher höchster Wert (Rekord) wird gespeichert.\\
Akzeptanzbedingung: $c(p) \ge Rekord - \sigma$.\\
$\sigma$ wird mit der Zeit abgesenkt.\\
$\Rightarrow$ Besser als Simuliertes Tempern, kann trozdem in lokalem Maxima hängen bleiben.\\

\subsubsection{Evolutionäre Algorithmen}
Eine Population ebsteht aus Individuen.\\
Individuen haben einen Genotyp / Merkamlsvektor $q \in \mathbb{R}^n$ und einen Phänotyp/Bewertungsfunktion $c(q)$.\\
Individuen können sich fortpflanzen. Haben sie 2 oder mehr Eltern $\Rightarrow$ Kreuzung, haben sie einen Elter $\Rightarrow$ Klone.\\
Die Größe der Population wird konstant gehalten.\\

\paragraph{Plus oder $(\mu + \lambda)$ Strategie}
\text{ }\\Die Population $Q$ ändert sich mit der zeit, ihre Größe $\mu = |Q|$ bleibt konstant.\\
Die $\mu$ Individuen mit der besten Fitness ($c(q$) und $\lambda$ Nachkommen bilden die nächste Generation, $\lambda$ Eltern sterben.\\
Eltern werden gleichverteilt aus $Q$ gewählt.\\
Es wird nicht gekreuzt, sondern nur geklont und mutiert.Zumindest steht nichts davon im Skript, sollte aber möglich sein...\\

\paragraph{Mehere Eltern}
\text{ }\\Es kann auch mehrere Eltern geben, die Merkamlsvektoren werden entweder Gemischt oder Gemittelt.\\


\paragraph{Allgemeine Strategie $((\mu, k, \lambda, p) - ES)$}
\begin{description}
\item[$\mu$] Populationsgröße - Für jede Generation konstant.
\item[$\lambda$] Anzahl der Nachkommen pro Generation
\item[$k$] Maximale Lebenszeit - $k = 1$ bei Komma-Strategie, $k=\infty$ bei Plus
\item[p] Anzahl der Eltern eines Individuums
\end{description}

\subsubsection{Genetische Algorithmen}
Merkmale in binärem Merkmalsvektor gespeichert.\\
Starke Eltern pflanzen sich häufiger fort als schwache.\\
\begin{description}
\item[fortpflanzung] Jedes Individuum wird mit der Wahscheinlichkeit $W(q) = \frac{c(q)}{\sum\limits_{p \in Q}c(p)}$ Elter. die $\mu$ Individuen erzeugen $\mu$ Nachkommen, nur diese überleben.

\item[Kreuzung] Von den $\mu$ Nachkommen werden p\% einer Kreuzung unterzogen. Die Kreuzungspaare sind zufällig.

\item[Mutation] Jedes Bit des Merkmalsvektors wird mit einer sehr kleinen Wahscheinlichkeit $p_m$ invertiert.
\end{description}

Schema-Theorem: Merkamle werden häufiger reproduziert, wenn sie 
\begin{enumerate}
\item durch weniger Bits dargestellt werden.
\item diese Bits eng zusammenstehen (im Vektor)
\item sie eine hohe Fitness bedeuten.
\end{enumerate}

Evolutionsstrategien $\Rightarrow$ konvergieren schneller, enden aber öfter in lokalem Max/Min.\\
Genetische Algorithmen $\Rightarrow$ bevorzugen Kreuzung statt Mutation, größere Sprünge im Suchraum, finden öfter globales Optimum, konvergieren schlechter.

\subsubsection{Partikelschwarmoptimierung (P-S-O)}
\begin{algorithm}[H]
	\caption{PSO}
	\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
	\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
        
        \Input{$n$ - Menge an Partikeln}
        \Output{$q$ - die beste gefundene Lösung}
        
        $\forall$ i : wähle $p_i(0), v_i(0)$ zufällig (Startposition und Geschwindigkeit der einzelnen Partikel)\\
        
        es gilt immer: $q_i$ bisher beste Position von $p_i$, $q = max(q_i)$\\
        \While{Abbruchgenauigkeit noch nicht erreicht}{
        \For{i = 0 , i < n; i++} {
                $v_i \leftarrow v_i \omega + (q_i - p_i) c_1 \cdot r_1 + (q - p_i) c_2 \cdot r_2$\\
                $p_i \leftarrow p_i + v_i$\\
            }
        }
        \Return q\\
\end{algorithm}

\subsection{Algorithmus von de Casteljau}
Der Algorithmus von de Casteljau ermöglicht die effiziente Berechnung einer beliebig genauen Näherungsdarstellung von Bézierkurven durch einen Polygonzug.\footnote{http://de.wikipedia.org/wiki/De-Casteljau-Algorithmus}

Der de Casteljau-Algorithmus angewendet auf ein Polygon \(B_0^0\) ist die Konkatenation von \(B_0^1\) und \(B_1^1\): \(C(B_0^0,t) := B_0^1 B_1^1\).

\begin{algorithm}[H]
	\caption{de Casteljau}
	\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
	\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}

	\Input{$b_0^0,...,b_n^0 \subset \mathbb{R}^d; t \in \mathbb{R}$}
	\Output{$b_0^0,...,b_0^n; b_0^n,...b_n^0 \subset \mathbb{R}^d$}
	\BlankLine

	\For{$k=1,...,n$}{
		\For{$i=0,...,n-k$}{
			$b_i^k \longleftarrow b_i^{k-1} \cdot (1-t) + b_{i+1}^{k-1} \cdot t$
		}
	}
\end{algorithm}

\paragraph{Der Lane-Riesenfeld-Algorithmus (LR-Algorithmus}
Dient dazu stückweise polynomielle Kurven (Splines) zu erzeugen. Dazu erzeugt er wie der de Casteljau-Algorithmus eine Folge von Polygonen(Kontrollpolygone), welche den Grenzwert der Folge(Limeskurve) definieren. Im Gegensatz zum de Casteljau-Algorithmus wird der LR-Algorithmus meist für biinfinite Kontrollpolygone $c_\mathbb{Z} := (c_i)_{i \in \mathbb{Z}} = ( ... c_{-1}c_0c_1 ...)$ beschrieben. Hierbei können endliche Polygone als biinfinite aufgefasst werden, bei denen nur endlich viele Kontrollpunkte $c_i$ von $\mathbb{D}$ verschieden sind.


\begin{algorithm}[H]
	\caption{Lane-Riesenfeld}
	\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
	\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}

	\Input{$c_{\mathbb{Z}}^0$ ein Polygon $ \subset \mathbb{R}^d$, $n \in \mathbb{N}_0$ der Grad, $m\in \mathbb{N}$ die Unterteilungstiefe}
	\Output{$c_{\mathbb{Z}}^m \subset \mathbb{R}^d$}
	\BlankLine

	\For{$k=1,...,m$}{
		\tcc{verdopple}
		\For{$i \in \mathbb{Z}$}{
			$d_{2i}^0 \longleftarrow d_{2i+1}^0 \longleftarrow c_{i}^{k-1}$
		}
		\For{$j=1, ... ,n$}{
			\tcc{mittele}
			\For{$i \in \mathbb{Z}$}{
				$d_i^j \longleftarrow (d_{i-1}^{j-1} + d_i^{j-1})*\frac{1}{2}$
				}
			}
		\tcc{bennene um}
		\For{$ i \in \mathbb{Z}$}{
			$c_i^k \longleftarrow d_i^n$
			}
	}
\end{algorithm}



\subsection{Naive Textsuche}
Im Folgenden ist \(A\) ein Alphabet, \(t = t_1,...,t_n \in A^n\) ein Text und \(s = s_1,...,s_m \in A^m\) mit \(m<n\) ein Suchtext.

Der einfachste Algorithmus besteht darin, ein so genanntes Suchfenster von der Länge der Suchmaske über den Text zu schieben. In jeder Position der Suchmaske werden die Symbole der Maske mit denen des darunterliegenden Textes verglichen. Wenn ein nicht übereinstimmendes Symbol gefunden wird, wird das Fenster um eine Position verschoben, und erneut ein Vergleich angestellt; wenn alle Symbole im Fenster übereinstimmen, ist die Suchmaske gefunden worden. Der Algorithmus endet, wenn der ganze Text vom Fenster abgesucht worden ist.\footnote{\url{http://de.wikipedia.org/wiki/String-Matching-Algorithmus\#Naiver_Algorithmus}}

\begin{algorithm}[H]
	\caption{Naive Suche}
	\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
	\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}

	\Input{$A,t,s$}
	\Output{Kleinstes $t_{i+1},...,t_{i+m} = s$}
	\BlankLine

	$i \longleftarrow 0$\newline
	\While{$i\leq n-m$}{
		$j \longleftarrow m$\newline
		\While{$j>0$ und $s_j=t_{i+j}$}{
			$j \longleftarrow j-1$
		}
		\BlankLine
		\eIf{$j=0$}{
			\Return{$i$}
		}{
			$i \longleftarrow i+1$
		}
	}
\end{algorithm}
Laufzeit in \(\mathcal{O}(n\cdot m)\), wenn der ganze Text abgesucht werden muss.

\subsection{Algorithmus von Boyer und Moore}
Das Muster wird am Anfang linksbündig unter den Text geschrieben und dann von rechts nach links Zeichen für Zeichen mit dem Text verglichen. Sobald ein Mismatch auftritt, berechnen zwei Heuristiken, wie weit das Suchmuster nach rechts verschoben werden kann.\footnote{\url{http://de.wikipedia.org/wiki/Boyer-Moore-Algorithmus}}

Es kommt vor, dass die beiden Heuristiken unterschiedliche Verschiebungen berechnen. Der Algorithmus wählt immer das Maximum der beiden Vorschläge, um das Muster nach rechts zu verschieben.

\subsubsection{Bad-Character-Heuristik}
Stimmt beim Vergleich des Musters mit dem Text von rechts nach links ein Zeichen des Musters nicht mit dem Zeichen des Textes überein („Bad-Character“), wird im Muster nach dem letzten Vorkommen dieses Bad-Characters gesucht und das Muster soweit verschoben, bis beide Buchstaben übereinander liegen. Existiert dieser Bad-Character nicht im Muster, wird das Muster um seine volle Länge nach rechts verschoben. Es kann vorkommen, dass die Bad-Character-Heuristik eine Verschiebung des Musters nach links vorschlägt. In diesem Fall wird um eine Position nach rechts geschoben.

Der Boyer-Moore-Algorithmus arbeitet am effizientesten, wenn er ein Zeichen vorfindet, das im Suchmuster nicht vorkommt. Die Bad-Character-Regel kommt dann zum Tragen. Dies ist sehr wahrscheinlich bei einem relativ kleinen Muster und einem großen Alphabet, was ihn für einen solchen Fall besonders geeignet macht. In diesem Fall arbeitet der Algorithmus mit einer Effizienz von \(\mathcal{O}(\frac{n}{m})\) Vergleichen.

\subsubsection{Good-Suffix-Heuristik}
Stimmt beim Vergleich des Musters mit dem Text von rechts nach links ein Suffix des Musters mit dem Text überein und tritt danach aber ein Mismatch auf, wird das Muster soweit nach rechts geschoben, bis ein Teilwort des Musters wieder auf das Suffix passt. Existiert das Suffix kein zweites Mal im Muster, wird das Muster um seine volle Länge nach rechts verschoben.

\subsubsection{Vorberechnung des größten, echten Präsuffixes pro Zeichen im Suchwort}
Ein Präfix eines Wortes \(w\), das zugleich ein Suffix von \(w\) ist, nennen wir \textit{Präsuffix} von \(w\). Weiter sei \(\gamma(j) := | geps(w_j)|\).

\begin{algorithm}[H]
	\caption{$\gamma$}
	\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
	\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}

	\Input{$s_1,...,s_m$}
	\Output{$\gamma(0,...,m-1$}
	\BlankLine

	$\gamma(m-1) \longleftarrow 0$\newline
	\For{i=m-1,...,1}{
		$j \longleftarrow m - \gamma(i)$\newline
		\While{$s_i \ne s_j$ und $m \ne j$}{
			$j \longleftarrow m - \gamma(i)$
		}
	}
	\BlankLine

	\eIf{$s_i = s_j$}{
		$\gamma(i-1) \longleftarrow m - j+1$
	}{
		$\gamma(i-1) \longleftarrow 0$
	}
\end{algorithm}

\subsubsection{Berechnung der Heuristik}
Die Heuristik berechnet für jedes Zeichen des Suchwort, wie weit dieses verschoben werden kann. Grundlage ist dabei die Gamma-Funktion, welche für jedes Zeichen des Suchworts die Länge des größten, echten Präsuffixes angibt.

\begin{algorithm}[H]
	\caption{$\gamma$}
	\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
	\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}

	\Input{$\gamma(0,...,m-1)$}
	\Output{$\sigma(1,...,m)$}
	\BlankLine

	\For{$j = 1,...,m$}{
		$\sigma(j) \longleftarrow m-\gamma(0)$
	}
	\BlankLine

	\For{$i=0,...,m-1$}{
		$k \longleftarrow m - \gamma(i) - i$\newline
		$j \longleftarrow m - \gamma(i)$
		\If{$\sigma(j) > k$}{
			$\sigma(j) \longleftarrow k$
		}
	}
\end{algorithm}
