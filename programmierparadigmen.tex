\chapter{Programmierparadigmen}

Zusammenfassung der Vorlesung "`Programmierparadigmen"' aus dem Wintersemester 2014.\footnote{\url{https://pp.info.uni-karlsruhe.de/lehre/WS201415/paradigmen/}}

\section{Funktionale Programmierung}



\section{Theoretische Grundlagen}


\section{Logische Programmierung}

\subsection{Einführung in Prolog}


\subsection{Backtracking}


\subsection{Arithmetik und Listen}


\subsection{Der Cut}


\subsection{Unifikation und Resolution}


\subsection{Spracherweiterungen}


\subsection{Constraint Logic Programming}



\section{Typinferenz}

\subsection{Typinferenz: $\lambda$-Kalkül}


\subsection{Typinferenz: \textit{let}-Polymorphismus}



\section{Grundlagen der Prallelprogrammierung}
Motivation: Leistungssteigerung über steigende Taktfrequenzen hinaus.

\subsubsection{Programmieransätze gemäß der Computerarchitektur}
\begin{itemize}
	\item Gemeinsamer Speicher: Jeder Prozessor kann jede Speicherzelle ansprechen (z.B. Multikernrechner)
	\item Verteilter Speicher: Jeder Prozessor hat seinen eigenen Speicher, Kommunikation über \textit{Message Passing} (z.B. bei Computerclustern)
\end{itemize}
Bei sequentieller Programmierung arbeitet der Prozessor nacheinander einzelne Befehle aus dem Arbeitsspeicher ab (von-Neumann-Architektur).

Bei paralleler Programmierung wird in der Theorie häufig das \textit{PRAM-Modell} mit einer beliebigen Anzahl an Prozessoren mit
\begin{itemize}
	\item jeweils lokalem Speicher
	\item und synchronem Zugriff auf globalen, gemeinsam genutzten Speicher (in der Praxis eher problematisch bei der Umsetzung.
\end{itemize}

\subsubsection{Flynn's Taxonomy}
\begin{enumerate}
	\item \textit{Single Instruction x Single Data:} Klassische von-Neumann-Architektur, ein Befehlsstrom arbeitet auf dem Speicher
	\item \textit{Single Instruction x Multiple Data:} Ein Befehl wird auf gleichartige Daten (z.B. Arrays) angewendet, typischerweise in Vektorprozessoren früherer Supercomputers
	\item \textit{Multiple Instruction x Multiple Data:} Verschiedene Prozessoren arbeiten auf verschiedenen Daten, beispielsweise in heutigen Multicore-Maschinen
	\item \textit{Multiple Instruction x Single Data:} Mehrere Befehle werden gleichzeitig auf den gleichen Daten ausgeführt, beispielsweise in redundanten Architekturen oder in den Pipelines moderner Prozessoren (Ansicht ist umstritten)
\end{enumerate}

\subsubsection{Herausforderungen}
\begin{itemize}
	\item Bereits schrittweise Parallelität benötigt Synchronisation
	\item Kommunikation der Prozesse untereinander
	\item Wettlaufbedingungen und Verklemmungen
\end{itemize}
Idealerweise lassen sich Probleme für Parallelverarbeitung so zerlegen, dass sie ohne Abhängigkeiten berechnet werden können; auch stückweise Parallelisierung ist möglich.

\subsubsection{Mögliche Beschleunigung}
\begin{itemize}
	\item Speedup: \(S(p) = \frac{T(n,1)}{T(n,p)} = \frac{Anzahl~mit~einem~Prozessor}{Aufwand~mit~p~Prozessoren}\)
	\item Amdahls Gesetz berechnet die maximale Beschleunigung, die durch Parallelverarbeitung erreicht werden kann: \(\frac{1}{(1-P)+\frac{P}{N}}\)
\end{itemize}


\subsection{Fortgeschrittene Konzepte in Java}

\subsubsection{Multithreading in Java}
\begin{itemize}
	\item Threads vor Java oft eher schwierig zu implementieren (in C/C++ zusätzliche Bibliotheken notwendig)
	\item In Java bereits in der Sprache enthalten
	\item Nicht vorgegeben ist allerdings die interne Implementierung des Multithreading in der jeweiligen VM
	\item Erben von der Klasse \textit{Thread} oder implementieren des Interface \textit{Runnable}
	\item \(stop()\) mit Hilfe von Pollen realisiert; ein Thread, der nicht beendet werden will, kann von außen nicht "`sauber"' beendet werden
	\item Rückgabewerte über \(Thread.join()\) realisierbar oder durch die Verwendung von \(Callables\) oder \(Futures\)
\end{itemize}


\subsection{\textit{C/C++} Wiederholung}


\subsection{Message Passing Interface (MPI)}


\subsection{Scala}


\subsection{X10}



\section{Compiler}

\subsection{Einführung}


\subsection{Lexikalische Analyse}


\subsection{Syntaktische Analyse}


\subsection{Semantische Analyse}


\subsection{Java-Bytecode}


\subsection{Codeerzeugung}



\section{Appendix A: Haskell}

\subsection{Funktionen}

\begin{table}[h]
\begin{tabularx}{\textwidth}{l|X|X}
	\textbf{\textit{drop}} & \(Int \rightarrow [a] \rightarrow [a]\) & Gibt die Liste ohne die ersten \textit{n} zurück \\
	\textbf{\textit{head}} & \([a] \rightarrow a\) & Gibt das erste Element einer nicht-leeren Liste zurück \\
	\textbf{\textit{length}} & \([a] \rightarrow Int\) & Gibt die Länge einer Liste oder eines Texts zurück \\
	\textbf{\textit{reverse}} & \([a] \rightarrow [a]\) & Gibt eine invertierte Form der Eingabeliste zurück \\
	\textbf{\textit{sort}} & \(Ord~a \Rightarrow [a] \rightarrow [a]\) & Gibt eine sortierte Form der Eingabeliste zurück \\
	\textbf{\textit{tail}} & \([a] \rightarrow [a]\) & Gibt eine Liste ohne Kopfelemente einer Eingabeliste zurück \\
	\textbf{\textit{take}} & \(Int \rightarrow [a] \rightarrow [a]\) & Gibt die ersten \textit{n} Elemente einer Liste zurück \\
	\textbf{\textit{zipWith}} & \((a \rightarrow b \rightarrow c) \rightarrow [a] \rightarrow [b] \rightarrow [c]\) & Kombiniert jeweils die Elemente zweier Listen über eine beliebige Funktion, beispielsweise \textit{(*)} \\
\end{tabularx}
\end{table}