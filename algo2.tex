\chapter{Algorithmen II}

Zusammenfassung der Vorlesung "`Algorithmen II"' aus dem Wintersemester 2014.\footnote{\url{http://geom.ivd.kit.edu/ws14_algo2.php}}


\section{Flussmaximierung}

\subsection{Flussnetzwerke}
\textbf{Ziel:} Berechnung des maximalen Flusses.

\subsubsection{Bestandteile}
\begin{itemize}
	\item Graph mit Quelle q und Senke s: \(G(V,E)\) mit \(E \subset V^2\)
	\item Kapazitätsfunktion \(k : V^2 \rightarrow \mathbb{R}_{+0}\), wobei \(\forall e \in V^2 \setminus E: k(e) = 0\)
\end{itemize}

\subsubsection{Flüsse}
Ein Fluss in F ist eine Funktion \(f:V^2\rightarrow\mathbb{R}\) mit den Eigenschaften:
\begin{enumerate}
	\item \(f \leq k\)
	\item \(\forall x,y \in V : f(x,y) = -f(y,x)\)
	\item \(\forall x \in V \setminus \{ q,s \}: 0 = \sum f(x,V) := \sum_{y\in V} f(x,y)\)
\end{enumerate}

\subsubsection{Bemerkungen}
\begin{itemize}
	\item Der negative Fluss soll lediglich die Darstellung vereinfachen und ist ansonsten uninteressant
	\item In alle Knoten außer in \(q\) und in \(s\) fließt immer so viel positiver Fluss rein wie raus
	\item Flussnetzwerke können zu einem Flussnetzwerk zusammengefasst werden (mit unendlichen Zu- und Abflüssen)
\end{itemize}


\subsection{Algorithmus von Ford und Fulkerson}
\begin{itemize}
	\item \textbf{Algorithmus}
	\begin{enumerate}
		\item Setze die Flüsse an alle Kanten gleich Null
		\item Solange es einen Pfad von \(q\) nach \(s\) gibt, erhöhe einen beliebigen Pfad
	\end{enumerate}
	\item Terminiert Ford-Fulkerson, ist \(f\) maximal
	\item Aufwand: \(\mathcal{O}(|E| \cdot max\{W_f | f~Fluss~in~F\})\), denn ein Pfad \(q \rightarrow^{*} s\) kann in \(|E|\) Schritten gefunden werden
\end{itemize}


\subsection{Algorithmus von Edmonds und Karp}
\begin{itemize}
	\item Idee: Anwendung von Ford-Fulkerson immer längs eines kürzesten Pfades (Breitensuche)
	\item Terminiert auch für beliebige reelle Kapazitäten
	\item Aufwand: \(\mathcal{O} (|E|^2 \cdot |V|)\)
\end{itemize}


\subsection{Präfluss-Pusch-Methode}
Jeder Knoten erhält zusätzlich eine Höhe und ein Reservoir, um vorübergehend beliebig viel Fluß speichern zu können.

\subsubsection{Operationen}

\paragraph{\(PUSCH(x,y)\)}
\begin{itemize}
	\item \textbf{Bedingungen}
	\begin{itemize}
		\item Überschuss bei \(x\) vorhanden: \(u(x) > 0, x \in V \setminus \{q,s\}\)
		\item \(x\) liegt höher als \(y\): \(h(x) - h(y) = 1\)
	\end{itemize}
	\item \textbf{Algorithmus}
	\begin{enumerate}
		\item Ermittle den Abfluss aus Überschuss und Restkapazität: \(min\{u(x), k_f(x,y)\}\)
		\item Erhöhe den Fluss auf der Kante \((x,y)\)
		\item Aktualisiere die Überschusswerte an \(x\) und \(y\)
	\end{enumerate}
\end{itemize}

\paragraph{\(LIFTE(x)\)}
\begin{itemize}
	\item \textbf{Bedingungen}
	\begin{itemize}
		\item Der Knoten ist weder \(q\) und \(s\)
		\item Überschuss bei \(x\) vorhanden
		\item \(x\) kann nur geliftet werden, wenn kein Pfad \(y \rightarrow x\) eine höhere Restkapazität aufweist: \(h(x) < h(y)\)
	\end{itemize}
	\item \textbf{Algorithmus}
	\begin{enumerate}
		\item Erhöhe \(x\): \(h(x) = 1 + min\{h(y)\}\)
	\end{enumerate}
\end{itemize}

\paragraph{PRAEFLUSS-PUSCH}
\begin{enumerate}
	\item \textbf{Initialisiere}
	\begin{enumerate}
		\item Alle Knoten außer \(q\) bekommen die Höhe \(0\) (\(h(q) = |V|)\)
		\item Alle Pfade von \(q\) bekommen die Kapazität nach \(k(x,y)\) zugewiesen, alle anderen Pfade \(0\)
	\end{enumerate}
	\item Solange es eine beliebige, erlaubte Operation gibt, führe diese aus
\end{enumerate}

\subsubsection{Laufzeit}
\[\mathcal{O} (|V|^2 \cdot |E|)\]


\subsection{Move-to-Front-Algorithmus}
Durch eine strukturierte Abarbeitung der Operationen wird \textit{Präfluss-Pusch} beschleunigt.

\begin{itemize}
	\item Idee: Strukturiertes Enladen der Knoten
	\item Die Knoten werden über eine Liste verwaltet
	\item Geliftete Knoten werden an die Spitze der Liste gesetzt
\end{itemize}

\subsubsection{Operationen}

\begin{minipage}{\textwidth}
LEERE
\begin{lstlisting}[frame=single,numbers=left,mathescape]
While $u(x) > 0$ {
	// Beginne mit dem hintersten Nachbarknoten
	Falls es einen puschbaren Nachbarknoten gibt {
		$PUSCH(x,y)$
	} sonst {
		$LIFTE(x)$
	}
}
\end{lstlisting}
\end{minipage}
\\\\
\begin{minipage}{\textwidth}
AN-DIE-SPITZE
\begin{lstlisting}[frame=single,numbers=left,mathescape]
Initialisiere wie in $PRAEFLUSS-PUSCH$
Generiere Knotenliste $L$
Forall Knoten {
	Bestimme Anzahl der Nachbarknoten
}
Forall $L$ {
	$LEERE(x)$
	Setze aktuellen Knoten an die Spitze von $L$,
				falls erhoeht wurde
}
\end{lstlisting}
\end{minipage}

\subsubsection{Laufzeit}
\[\mathcal{O}(|V|^3)\]



\section{Zuordnungsprobleme}
\textbf{Ziel:} Verteilung verschiedener Aufgaben auf eine Gruppe von Personen mit unterschiedlichen Fähigkeiten.

\subsection{Paaren in bipartiten Graphen}
\begin{itemize}
	\item Eine Paarung beinhaltet zwei Knoten exklusiv
	\item Eine Paarung heißt maximal, wenn es keine bessere Paarung gibt
	\item Maximale Paarung über Flußmaximierung: Ergänzung des bipartiten Graphs um Quelle und Senke
\end{itemize}


\subsection{Paaren in allgemeinen Graphen}
Sei \(G=(V,E)\) ein Graph mit einer Paarung \(P\) und einer maximalen Paarung \(Q\).

\subsubsection{Symmetrische Differenz}
\[D:=(P\setminus Q) \cup (Q \setminus P)\]
Die Kanten dieser Wege liegen alternierend in \(P\) und \(Q\) \(\rightarrow\) Zyklen haben eine gerade Länge.

\subsubsection{Definition}
Es gibt \(k= |Q|-|P|=|Q\setminus (P \cap Q)| - |P\setminus (P \cap Q)|\) Wege, auf denen \(P\) vergrößert werden kann. Die Endkanten liegen beiden \(\in Q\).

\subsubsection{Folgerung}
Man kann eine maximale Paarung durch sukzessive Vergrößerungen finden.

\paragraph{Algorithmus zur Vergößerung}
\begin{enumerate}
	\item Suche \((x,y) \in E\), wobei \(x\) mit keinem \(z\in V\) gepaart
	\item Setze \((x,y)\) durch Breitensuche zu einem alternierden Weg \(W\) ungerade Länge fort
\end{enumerate}

\subsubsection{Blüten}
\begin{itemize}
	\item Zu Problemen kommt es bei sogenannten Blüten
	\item Lösung: Man schrumpft die Blüten ohne ihren Stil zu einem Knoten
\end{itemize}

\subsubsection{Aufwand der Suche nach vergrößernden Wegen}
\[\mathcal{O}(\sqrt{|V|} \cdot |E|)\]


\subsection{Maximal gewichtete Paarung}
\textbf{Gesucht:} Maximal gewichtete Paarung eines ungerichteten Graph:
\[\Gamma(P) := \Sigma \gamma (P)\]

\subsubsection{Annahme}
Man kann eine maximal gewichtete Paarung finden, indem eine maximal gewichtete Kante iterativ durch einen vergrößernden Weg zu einer nächstgrößeren Paarung vergrößert wird.

\paragraph{Aufwand}
\[\mathcal{O}(min\{|V|^3, |V| \cdot |E| \cdot log|V|\})\]



\section{Stochastische Algorithmen}

\subsubsection{Begriffe}
\begin{itemize}
	\item Las-Vegas-Algorithmus: Randomisierter Algorithmus, der immer ein korrektes Ergebnis liefert, wenn er terminiert.\footnote{\url{http://de.wikipedia.org/wiki/Las-Vegas-Algorithmus}}
	\item Monte-Carlo-Algorithmus: Randomisierte Algorithmen, die mit einer nach oben beschränkten Wahrscheinlichkeit ein falsches Ergebnis liefern dürfen. Dafür sind sie im Vergleich zu deterministischen Algorithmen häufig effizienter.\footnote{\url{http://de.wikipedia.org/wiki/Monte-Carlo-Algorithmus}}
\end{itemize}

\subsection{Erwartungswert}
Der Erwartungswert einer Zufallsvariablen beschreibt die Zahl, die die Zufallsvariable im Mittel annimmt.\footnote{\url{http://de.wikipedia.org/wiki/Erwartungswert}}

\subsubsection{Sigma-Additivität}
\[\mathbb{E}\lbrack \Sigma X_i\rbrack = \Sigma E \lbrack X_i\rbrack\]


\subsection{Quicksort}
\begin{itemize}
	\item Sortieren durch stochastisches Teilen
	\item Aufwandsabschätzung anhand der durchgeführten Vergleiche
\end{itemize}


\subsection{Minimaler Schnitt}

\subsubsection{Definitionen}
\begin{itemize}
	\item Ereignisse: Die Teilmengen einer Stichprobenmenge
	\item Bedingte Wahrscheinlichkeit: \(Pr \lbrack E_1 | E_2 \rbrack := \frac{Pr\lbrack E_1 \cap E_2 \rbrack}{Pr\lbrack E_2 \rbrack} \)
	\item Multigraph: Kanten können mehrfach vorkommen
\end{itemize}

\subsubsection{Algorithmus zur Berechnung des Schnitts}
\begin{minipage}{\textwidth}
SCHNITT
\begin{lstlisting}[frame=single,numbers=left,mathescape]
While $|V| \geq 3$ {
	Waehle zufaellig eine Kante $(x,y)$
	Entferne alle $(x,y)$ aus $E$
	Verschmelze $x$ mit $y$
}
\end{lstlisting}
\end{minipage}



\section{Technik der Spieltheorie}
Aufwandsabschätzung von Las-Vegas-Algorithmen nach unten.

\subsection{Nullsummenspiele}
\begin{itemize}
	\item Bedingung: \(Gewinn(A) + Gewinn(B) = 0\)
	\item Definiert durch eine \(n \times m\) Matrix \(M\)
\end{itemize}

\subsubsection{Strategien}
\begin{itemize}
	\item Die Zeilen von \(M\) heißen Strategien von \(A\), die Spalten von \(M\) heißen Strategien von \(B\)
	\item Zeile \(i\) ist eine optimale Strategie für \(A\) und maximiert den Mindestgewinn: \(min_j~M_{ij}\)
	\item Spalte \(j\) ist eine optimale Strategie für \(B\) und minimiert den Maximalverlust: \(max_j~M_{ij}\)
	\item Wählen beide optimale Strategien: \(max_i~min_j~M_{ij} \leq Gewinn(A) \leq min_j~max_i~M_{ij}\)
\end{itemize}


\subsection{MiniMax-Theorem}

\subsubsection{Definitionen}
\begin{enumerate}
	\item \(p := \lbrack p_1,...,p_m \rbrack \) bezeichnet die \textit{gemischte Strategie} von \(A\)
	\item \(q := \lbrack q_1,...,q_n \rbrack \) bezeichnet die \textit{gemischte Strategie} von \(B\)
	\item Erwartungswert des Gewinns von \(A\): \(\mathbb{E}\lbrack Gewinn(A) \rbrack = p^T \cdot M \cdot q\)
	\item Optimale Strategie von \(A\): \(min_q~(p^T \cdot M \cdot q)\)
	\item Optimale Strategie für beide: \\ \(max_p~min_q~(p^T \cdot M \cdot q) \leq E \lbrack Gewinn(A) \rbrack \leq min_q~max_p~(p^T \cdot M \cdot q)\)
\end{enumerate}

\subsubsection{Von-Neumanns-MiniMax-Theorem}
\[max_p~min_q~(p^T \cdot M \cdot q) = min_q~max_p~(p^T \cdot M \cdot q)\]

Für ein festes \(p\) wird \(p^T \cdot M \cdot q\) minimiert, wenn die j-te Koordinate von \(p^T \cdot M\) minimal ist (siehe Satz von Loomi).


\subsection{Yoas Technik}
Verwendung des MiniMax-Theorems zur Laufzeitabschätzung von stochastischen Algorithmen für ein Problem \(P\):
\(B\) wählt einen Algorithmus \(A \in \{A_1,...,A_m\}\) und \(A\) wählt eine Eingabe \(E \in \{E_1,...,E_n\}\)
\begin{itemize}
	\item Worst-case-Laufzeit von \(A\): \(max_i~M_{ij}\)
	\item Deterministische Laufzeit von \(A\): \(min_j~max_i~M_{ij}\)
	\item Best-case-Laufzeit von \(A\): \(min_j~M_{ij}\)
	\item Stochastische Komplexität (Laufzeit) von \(A\) bzgl. \(P\): \(max_i~min_j~M_{ij} =: K_s\)
	\item Erwartungswert der Laufzeit: \(\mathbb{E}\lbrack Laufzeit \rbrack: \sum_{ij} p_i \cdot M_{ij} \cdot q =: p^T \cdot M \cdot q\)
	\item Verteilungskomplexität: \(K_v := max_p~min_q~(p^T \cdot M \cdot q)\)
\end{itemize}

\subsubsection{Folgerung}
\[K_s \leq K_v \leq K_d\]

\subsubsection{MiniMax-Theorem von Yao}
\[\forall p,q: min_j~(p^T \cdot M \cdot e_j) \leq K_v \leq max_i~(e_i^T \cdot M \cdot q)\]
Hiermit kann die worst-case-Laufzeit aller stochastischer Algorithmen durch die Laufzeit des schnellsten deterministischen Algorithmus nach unten abgeschätzt werden.


\subsection{Spielbaumauswertung}
Ein binärer Spielbaum ist ein balancierter Binärbaum gerader Höhe \(2k\) mit Knotenwert \(x \in \{0,1\}\) und den Kindknoten \(y \in \{0,1\}\) und \(z \in \{0,1\}\). Es gilt:
\[Wert(x) = Wert(y) \downarrow Wert(z)\]

\subsubsection{Bestimme den Wurzelwert aus den Blattwerten}
\begin{minipage}{\textwidth}
WERT(x)
\begin{lstlisting}[frame=single,numbers=left,mathescape]
Ermittle die Kindknoten $(y,z)$ von $x$ in stochastischer Reihenfolge
Ermittle $w = WERT(y)$
Falls $w==1$ gib $0$ aus, ansonsten gib $(0 \downarrow WERT(z))$ aus
\end{lstlisting}
\end{minipage}



\section{Algorithmen für Geometrische Probleme}

\subsection{Binäre Zerlegung der Ebene}

\subsubsection{Vorgehen}
Teile die affine Ebene \(A\) anhand einer Halbgeraden \(S_1\) in die Ebenen \(A_0\) und \(A_1\). Fahre rekursiv fort.

\subsubsection{Raumzerlegungsbaum}
Die entstandenen Aufteilungen lassen sich über einen binären Raumzerlegungsbaum darstellen. Anwendung beispielsweise in der Computergrafik (Maleralgorithmus).
Ziel dabei: Möglichst kleine RZBs mit wenigen Zerlegungen.


\subsection{Binäre Zerlegung des Raums}
Folgender Algorithmus erzeugt binäre RZBs für den Raum:

\subsubsection{Eingabe}
Ein Polyeder \(P \subset \mathbb{R}^3\) sowie orientierte, planare, disjunkte Polygone \(P_1,...,P_n \subset \mathbb{R}^3\).

\subsubsection{Vorgehen anschaulich}
\begin{enumerate}
	\item Sortiere Polygone aus, die keine Schnittfläche mit dem Polyeder gemeinsam haben
	\item Falls es ein Polygon gibt, das den Polyeder komplett teilt, nehme dieses zum Trennen. Gibt es keines nehme das erste aus \(Q\)
	\item Teile den Polyeder und fahre rekursiv fort. Alle aktuellen Polygone werden mitübergeben und im nächsten Iterationsschritt aussortiert
\end{enumerate}

\begin{minipage}{\textwidth}
BRZ
\begin{lstlisting}[frame=single,numbers=left,mathescape]
$k = 1$
Forall $P_i$ {
	Bestimme Schnittflaeche mit $P$
	Falls es eine Schittflaeche gibt: $k++$
}
$l = 1$
Falls es ein $j$ gibt: $Q_j$ zerlegt $P$ {
	$l = j$
}
Wurzel = $Q_l$
Falls $k \geq 3$ {
	$Q$ = Schnittmenge von $P$ und dem li. HR von $Q_l$
	linker Wurzelteilbaum = $BRZ(Q,Q_1,...,Q_{k-1})$
	$Q$ = Schnittmenge von $P$ und dem re. HR von $Q_l$
	rechter Wurzelteilbaum = $BRZ(Q,Q_1,...,Q_{k-1})$
}
Return Wurzel und Teilbaeume
\end{lstlisting}
\end{minipage}


\subsubsection{Laufzeit}
\(Z\) bezeichnet die Anzahl der von \(BRZ\) erzeugten Teilsegmente der \(P_i\). Es gilt:
\[\mathbb{E}\lbrack Z \rbrack \in \mathcal{O}(n^2)\]


\subsection{Konvexe Hüllen}
Wir fassen den \(\mathbb{R}^3\) als affinen Raum \(A\) auf und bezeichnen dessen Elemente als Punkte und ihre Differenzen als Vektoren. Die konvexe Hülle einer Teilmenge ist die kleinste konvexe Menge, die die Ausgangsmenge enthält\footnote{\url{http://de.wikipedia.org/wiki/Konvexe_H\%C3\%BClle}} (alle weiteren Elemente liegen in dem Raum, den die konvexe Hülle aufspannd).


\subsection{Dualität}

\subsubsection{Hyperebene}
Die Lösungsmenge einer linearen Gleichung
\[u^T \cdot x = 1, u \in \mathbb{R}^n\]
heißt Hyperebene von \(A\), d.h.
\[u* := \{x \in A~|u^T \cdot x = 1\}\]

\subsubsection{Halbebene}
Als \(u \in A\) wird der zu \(u*\), \(x*\) zum Punkt \(x\) duale Halbebene bezeichnet.

\subsubsection{Dualraum}
\[A* = \{x*~|~x \in A\}\]

\subsubsection{Halbraum}
Die Lösung der Ungleichung
\[u^T \cdot x \leq 1, u \ne 0,\]
bildet den Halbraum \(u^{\leq}\).


\subsection{Beziehungen zwischen Knoten, Kanten und Facetten}
Die Formeln gelten nicht nur für Polyeder, sondern für beliebige geschlossene Netze mit topologischen Geschlecht \(2\), d.h. Netze, die bis auf Verbindungsformen eine Kugeloberfläche darstellen.

\subsubsection{Eulers Formel}
Für einen Polyeder mit \(v\) Knoten, \(e\) Kanten und \(f\) Seiten gilt:
\[v-e+f=2\]

\subsubsection{Triangulation von Polyedern}
Durch die Hinzunahme von Kanten kann ein Polyeder trianguliert werden. Werden \(k\) Kanten hinzugefügt, gilt:
\[3(f+k) = 2(e+k)\]
Daraus folgt der mittlere Knotengrad
\[\frac{2e}{v} \leq 6\]
und dazu die mittlere Kantenzahl pro Seite
\[\frac{2e}{f} \leq 6\]



\section{Bewegungsplanung bei unvollständiger Information}
\begin{itemize}
	\item Suche nach einer Lösung, über die auch zur Laufzeit nur Teilwissen bekannt ist
	\item Qualität der Ausgabe ist interessanter als die Laufzeit
	\item Es kann sein, dass keine oder keine eindeutige Lösung existiert
\end{itemize}


\subsection{Ausweg aus einem Labyrinth}
Wir betrachten ein Labyrinth \(L\) und einen Roboter \(R\) mit Tastsensor und Drehwinkelmessgerät.
\\\\
\begin{minipage}{\textwidth}
PLEDGE-Strategie
\begin{lstlisting}[frame=single,numbers=left,mathescape]
While $R \in L$ {
	Gehe vorwaerts bis Wand kontaktiert wird
	While $R \in L$ OR Drehwinkel = $0$ {
		Gehe links der Wand
	}
}
\end{lstlisting}
\end{minipage}


\subsection{Zum Ziel in unbekannter Umgebung}
Gegeben sind \(P_1,...P_n\) disjunkte Polygone, ein Roboter \(r\), ein Startpunkt \(s\) und ein Ziel \(z\).
\\\\
\begin{minipage}{\textwidth}
WANZE
\begin{lstlisting}[frame=single,numbers=left,mathescape]
While $r \ne z$ {
	Laufe in Richtung $z$ bis $r == z$
			OR $r$ nicht aus einem Polygon herauskommt
	Falls $r \ne z$ {
		Suche den kuerzesten Punkt $q$ an $P_i$ zu $z$
		Laufe zu $q$
	}
}
\end{lstlisting}
\end{minipage}
Wanze terminiert.

\subsubsection{Universelles Steuerwort}
Jedes Steuerwort \(w \in \{z,l,r\}*\) entspricht einer Bewegung, die auf \(s\) angewendet den Endpunkt \(w(s)\) ergibt, der dieser Bewegung entspricht. Beispiel: \(w = zr^3zl^3z\)
\\\\
\textbf{Satz:} Es gibt ein universelles Steuerwort \(w\), das für alle Startpunkte zum gegebenen Ziel \(z\) führt. \(\rightarrow \) Da \(r\) alle endlichen Steuerworte erzeugen kann, erreicht er spätestens mit dem universellen sein Ziel. Ein Zielkompass genügt also zur Zielfindung.


\subsection{Behälterproblem}
\textbf{Ziel:} Zerlege eine Folge \(A := (a_1,...,a_m)\) in möglichst wenig Teilfolgen \(A_j\) mit einer bestimmten Größe \(h\) (Problem ist NP-hart).
\\\\
\begin{minipage}{\textwidth}
FIRST-FIT
\begin{lstlisting}[frame=single,numbers=left,mathescape]
For $i = 1,...,m$ {
	Fuege $a_1$ dem ersten Behaelter hinzu | $a_i + A_j \leq h$
}
\end{lstlisting}
\end{minipage}
Die Laufzeit is in \(\mathcal{O}(n)\).

\subsubsection{Kompetivität}
Größe der Lösung eines Problems \(P\)
\begin{itemize}
	\item Optimaler Algorithmus: \(k_{opt}: \epsilon \rightarrow \mathbb{N}\)
	\item Korrekter Algorithmus \(A\): \(k_A: \epsilon \rightarrow \mathbb{N}\)
\end{itemize}
Es gilt:
\[k_A \leq a+c\cdot k_{opt}~(a,c \in \mathbb{R})\]
\(c\) bezeichnet den Kompetivitätsfaktor der Lösung.


\subsection{Türsuche}
\textbf{Ziel:} Finde die Tür an einer langen, unüberschaubaren Wand.
\\\\
\begin{minipage}{\textwidth}
Türsuche
\begin{lstlisting}[frame=single,numbers=left,mathescape]
$i = 1$
While Tuer nicht gefunden {
	gehe $i$ Meter in eine Richtung
	aendere Laufrichtung und gehe zurueck
	$i++$
}
\end{lstlisting}
\end{minipage}
Die Türsuche ist 9-kompetiv.


\subsection{Sternsuche}
Verallgemeinerung der Türsuche. Ziel: Finden des Ziels \(z\) vom Startpunkt \(s\) aus mit Hilfe von \(m\) wachsenden Halbgeraden.
\\\\
\begin{minipage}{\textwidth}
Sternsuche
\begin{lstlisting}[frame=single,numbers=left,mathescape]
# berechne Halbgeraden
Forall $i \in \mathcal{N}_0$ {
	$f_i = (\frac{m}{m-1})^i$
}
$i = 0$
While $z$ nicht gefunden {
	gehe $f_i$ Einheiten auf $H_i$ entlang und zurueck
	$i++$
}
\end{lstlisting}
\end{minipage}


\subsection{Suche in Polygonen}

\subsubsection{Definitionen}
\begin{itemize}
	\item Ein Polygon \(P\) heißt geschlossen, wenn gilt \(p_m = p_1\).
	\item Ein Polygone \(P\) heißt einfach, wenn kein Punkt von \(P\) in zwei Kanten liegt.
\end{itemize}
Es gibt keine kompetitive Strategie.

\subsubsection{Baum der kürzesten Wege}
\begin{itemize}
	\item Die kürzesten Wege \(s\) zu den Ecken von \(P\) bilden den Baum der kürzesten Wege (BkW) von \(P\) und \(s\)
	\item Absuchen der Wege zu den Blättern per Sternsuche
	\item Speichern der bereits erreichten Punkte als Zwischenstopps für spätere Punkte
\end{itemize}



\section{Lineare Programmierung}
\textbf{Ziel:} Maximierung linearer Funktionen mit linearen Nebenbedingungen, beispielsweise zur Bestimmung des maximalen FLusses in einem Netzwerk oder um das MiniMax-Theorem zu beweisen.

\subsection{Lineares Programm}
Die lineare Ungleichung
\[y := \upsilon^T \cdot x + u \geq 0\]
beschreibt den Halbraum mit Normalenvektor \(\upsilon\).

\subsubsection{Konvexer Polyeder}
Die Nebenbedingungen
\[y_i := a_i^T \cdot x + a_i \geq 0,~i = 1,...,l\]
bilden ein konvexes Polygon \(s\), das in der linearen Programmierung \textit{Simplex} genannt wird. Das gesuchte Maximum, das durch die Nebenbedingungen begrenzt wird, befindet sich innerhalb des Simplex.
\\\\
\textbf{Ziel:} Maximierung einer linearen Zielfunktion über dem Simplex \(s\):
\[z := z^T \cdot x = max!\]
\[y := A\cdot x + a \geq 0\]

\subsubsection{Normalform des linearen Programms}
\[z = c^T\cdot \bar{y} + c \stackrel{!}{=} max\]
\[y' \geq 0\]
\[y'' = B \cdot y' + b \geq 0\]

\[\begin{array}{c|ccc|c|}
	& & y' \geq 0 & & 1 \\
	\hline
	& & & & \\
	y''= & & B & & b \\
	& & & & \\
	\hline
	z= & & c^T & & c \\
	\hline
\end{array}\]
\(c\) wird maximiert.


\subsection{Eckentausch}
\textbf{Ziel:} Um \(z\) zu maximieren, machen wir sukzessive neue \(y_i\) zu neuen Koordinaten, so dass der Ursprung von Ecke zu Ecke wandert und der Wert von \(z\) im Ursprung wächst.
\\\\
\textbf{Vorgehen}: Tausche immer eine Koordinate von \(y'\) mit einer von \(y''\).
\[\begin{pmatrix}
	a_{11}v_1 & ... &a_{1n}v_n & u_1\\
	.   &		.	& .   & . \\
	.   &		.	& .   & . \\
	.   &		.	& .   & . \\
	a_{m1}v_1 & . & a_{mn}v_n & u_m
\end{pmatrix}\]
Ist \(a_{rs} \ne 0\) können \(u_r\) und \(v_s\) getauscht werden. Ein beliebiges \(a_{rs}\) fungiert als Pivotelement. 
\\\\\\
\begin{minipage}{\textwidth}
AUSTAUSCH(A, r, s)
\begin{lstlisting}[frame=single,numbers=left,mathescape]
Forall $i \ne r$, $j \ne s$ {
	$a_{ij}' = a_{ij} - \frac{a_{is} \cdot a_{rj}}{a_{rs}}$
}
# Pivotzeile
Forall $i == r$, $j \ne s$ {
	$a_{ij}' = -\frac{a_{ij}}{a_{rs}}$
}
# Pivotspalte
Forall $i \ne r$, $j == s$ {
	$a_{ij}' = \frac{a_{ij}}{a_{rs}}$
}
# Pivot
Forall $i == r$, $j == s$ {
	$a_{ij}' = \frac{1}{a_{rs}}$
}
\end{lstlisting}
\end{minipage}


\subsection{Der Simplexalgorithmus}
\textbf{Ausgangspunkt:} Ein lineares Programm in Normalform
\[z = c^T \cdot x + c = max!,\]
\[x \geq 0,\]
\[B \cdot x + b \geq 0,\]
ausführlich:
\[\begin{array}{c|ccc|c|}
	& x_1 & ... & x_n & 1 \\
	\hline
	y_1= & b_{11} & ... & b_{1n} & b_1 \\
	\vdots & \vdots & & \vdots & \vdots \\
	y_m= & b_{m1} & ... & b_{mn} & b_n \\
	\hline
	z= & c_1 & ... & c_n & c \\
	\hline
\end{array}\]
\\\\
\textbf{Vorgehen:} Iteratives Tauschen von \(y_r\) mit \(x_s\).
\\\\\\
\begin{minipage}{\textwidth}
SIMPLEX
\begin{lstlisting}[frame=single,numbers=left,mathescape]
# Bringe Problem in Normalform
Forall Bedingungen {
	Formuliere Bedingung als Ungleichung in Matrixzeile
	Falls Bedingung obere Schranke hat {
		invertiere Ungleichung
	}
}

# Tausche
While moeglich {
	Waehle kleinsten Matrixwert als Pivotelement
	Forall Zeilen {
		Ermittle $\frac{b_i}{b_is}$
		x = davon groesster, noch negativen Wert
	}
	Tausche Spalte(Pivotelement) mit Zeile(x)
}
\end{lstlisting}
\end{minipage}


\subsection{Berechnung der Normalform}
\begin{itemize}
	\item Für die Überführung eines linearen Programms in die Normalform muss eine Ecke des Simplex zum Ursprung gemacht werden
	\item Problem: Im Allgemeinen sind die Ecken des Simplex nicht bekannt
	\item Es sind allerdings einer oder mehrere Punkte bekannt, die zum Ursprung gemacht werden können
	\item \textbf{Vorgehen}
	\begin{enumerate}
		\item Tauschen von \(y_r\) mit \(x_s\) auf der Hauptdiagonalen. Der Ursprung wandert auf einer Koordinatenachse
		\item Streichen der getauschten Zeile
	\end{enumerate}
\end{itemize}


\subsection{Flussmaximierung}
Die Suche nach einem maximalen Fluss in einem Flussnetzwerk kann als lineares Programm angesehen werden.

\textbf{Gegeben:} Gerichteter Graph mit Kapazitätsbeschriftung.
\\\\
Daraus ergibt sich das lineare Programm:
\[z = x_1 + x_2 = max!\]
Nebenbedingungen:
\begin{itemize}
	\item \textbf{Flusserhaltung}
	\begin{itemize}
		\item Für jeden Knoten die Summe der aus- und eingehenden Flüsse: z.B. \(x_1-x_3-x_4 \geq 0\)
		\item Für jeden Knoten die negierten aus- und eingehenden Flüsse: z.B. \(-x_1+x_3+x_4 \geq 0\)
	\end{itemize}
	\item \textbf{Kapazitätsbeschränkung}
	\begin{itemize}
		\item Für alle Kanten die Beschränkung des Flusses: z.B. \(5-x_1 \geq 0\)
		\item An allen Kanten muss der Fluss positiv sein: z.B. \(x_1 \geq 0\)
	\end{itemize}
\end{itemize}


\subsection{Duale lineare Programme}
Das lineare Programm
\[x \geq 0\]
\[B\cdot x + b \geq 0\]
\[c^T \cdot x + c = max!\]
wird durch die Matrix \(\mathbb{B} := \begin{pmatrix} B & b \\ c^T & c\end{pmatrix}\) repräsentiert. Durch Eckentausch kann sie auf eine Normalform \(\overline{\mathbb{B}}\) gebracht werden.

\subsubsection{Dualitätsgesetz}
Das lineare Programm
\[y \geq 0\]
\[B^T \cdot y + c \leq 0\]
\[b^t \cdot y + c = min!\]
hat die Normalform \(\overline{\mathbb{B}}^T\), die Lösung \(\overline{y}=0\) und den Minimalwert \(\overline{c}\).
\\\\
\textbf{Definition:} Die beiden linearen Programme heißen dual zueinander.
\\\\
\textbf{Bemerkung:} Das zweite Programm kann umgeschrieben und mit \textit{SIMPLEX} gelöst werden. Gleichzeitig löst man damit das erste Programm. Es ist das Lösen des \textit{primalen Programms} in dualer Form.


\subsection{Beweis des MiniMax-Theorems}
Mit Hilfe des Dualitätssatzes für lineare Programme kann das MiniMax-Theorem
\[max(x \in W_M)~min(y \in W_n)~x^T\cdot A\cdot y = min(y \in W_n)~max(x \in W_m)~x^T\cdot A \cdot y\]
bewiesen werden. Auf Grund des SIMPLEX-Algorithmus ist es äquivalent zu
\[max(x)~min(i)~x^T\cdot A \cdot e_j = min(y)~max(i)~e_i^T\cdot A \cdot y\]

\subsubsection{Linke Seite}
Auf der linken Seite wird
\[x_0 := min(i)~x^T\cdot A \cdot e_j\]
maximiert. Da \(x_0\) mit \(x\) wächst erhält man das lineare Programm
\\\\
\[\begin{array}{|cc|c|}
x & x_1 & 1 \\
\hline
A^T & -b & 0 \\
-a^T & 0 & 1 \\
\hline
0^T & 1 & 0 \\
\hline
\end{array}\]

\subsubsection{Rechte Seite}
Analog wird die rechte Seite
\[max(i)~e_i^T\cdot A \cdot y\]
minimiert. Man erhält das lineare Programm
\\\\
\[\begin{array}{|cc|c|}
y & x_0 & 1 \\
\hline
A & -a & 0 \\
-b^T & 0 & 1 \\
\hline
0^T & 1 & 0 \\
\hline
\end{array}\]

\subsubsection{Folgerung}
Da die rechte Seite dual zur linken Seite, folgt das MinMix-Theorem.


\subsection{Ausgleichen mit der Maximumsnorm}
Sei
\[Ax = a\]
ein überbestimmtes Gleichungssystem, d.h. für alle \(x\) ist das Residuum
\[r := \begin{bmatrix} r_1 \\ \vdots \\ r_n \end{bmatrix} := Ax - a \ne 0.\]
\textbf{Ziel:} Minimieren von
\[r := \parallel r \parallel_{\infty} := max(i)~|r_i|\]
mit Hilfe eines linearen Programms
\[-A\overline{x} + ax_0 + e \geq 0\]
\[A\overline{x} - ax_0 + e \geq 0\]
\[x_0 = max!\]

\subsubsection{Vorgehen zur Berechnung}
\textbf{Gegeben:} Lineares, überbestimmtes Gleichungssystem
\begin{enumerate}
	\item Aufstellen des linearen Programms
	\begin{enumerate}
		\item Formulieren der Nebenbedingungen und der negierten Nebenbedingungen
		\item Nebenbedingungen im linearen Programm gleich \(1\) setzen
	\end{enumerate}
	\item Berechnen des Maximums nach dem SIMPLEX-Algorithmus
	\item Berechnung der Normalform
	\item Berechnung von \(x_1\) aus \(r\) (\(z = x_0\))
\end{enumerate}


\subsection{Aufwand}
\begin{itemize}
	\item Worst-Case-Laufzeit: \(\Omega(m^{\frac{n}{2}})\)
	\item Laufzeit in der Praxis: \(\mathcal{O}(m^2n)\)
	\item Lineare Programme sind NP-hart (Überführung in Rücksackproblem möglich)
\end{itemize}



\section{Zufallsgesteuerte Optimierung}

\subsection{Definitionen}

\subsubsection{Optimierungsaufgabe}
Eine Optimierungsaufgabe besteht aus
\begin{itemize}
	\item einem Suchraum \(Q\), der Teil eines Zustandraumes \(Z\) ist,
	\item einer Bewertungsfunktion (Kostenfunktion) \(c:Z \rightarrow \mathbb{R}\), die jedem Zustand \(q\) seine Kosten zuordnet,
	\item Nebenbedingungen.
\end{itemize}
\textbf{Gesucht:} Ein \(q \in Q\) mit minimalen oder maximalen Kosten.

\subsubsection{Kombinatorische Optimierungsaufgabe}
Eine Optimierungsaufgabe heißt kombinatorisch, wenn der Suchraum \(Q\) diskret ist.

\subsubsection{Globales/Lokales Optimum}
\begin{itemize}
	\item \(q \in Q\) heißt \textit{globales Optimum}, wenn für alle anderen Lösungen \(p \in Q\) gilt: \(c(q) \leq c(p)\)
	\item \(q \in Q\) heißt \textit{lokales Optimum}, wenn für alle Nachbarn \(p \in Q\) von \(q\) gilt: \(c(q) \leq c(p)\)
\end{itemize}


\subsection{Gradientenverfahren}
\begin{itemize}
	\item Verfahren anschaulich: Der Algorithmus nähert sich schrittweise, nur mit Kenntnis der nächsten Nachbarn dem Maximum (Minimum). Ist kein Aufstieg (Abstieg) mehr möglich, so terminiert er
	\item Problem: Eventuell ist nur ein lokales Maximum (Minimum) erreicht
	\item \textbf{Nicht anwendbar:}
	\begin{itemize}
		\item Berechnung unangemessen aufwendig
		\item Lokale Optima auf dem Weg zum globalen Optimum
	\end{itemize}
\end{itemize}


\subsection{Suchverfahren}
Definition eines Suchbaums, der beginnend bei seinem Anfangszustand durchsucht werden kann.

\subsubsection{Beispiel: Handlungsreisender}
\begin{itemize}
	\item Gesucht: Eine möglichst günstige Rundreise
	\item Prinzip: Iterative Auswahl des "`besten"' Kindknotens
	\item \textbf{Probleme}
	\begin{itemize}
		\item Bestimmung des "`besten"' Nachfolgers kann sehr aufwendig sein
		\item Eventuell sind Rückschritte nötig, da der Weg zur optimalen Lösung nicht monoton verbessernd ist
	\end{itemize}
\end{itemize}


\subsection{Stochastische Verfahren}

\subsubsection{Probleme bisher}
\begin{itemize}
	\item Bei kombinatorischem steilsten Abstieg müssen die Kosten jeweils für alle Nachfolger berechnet werden (hoher Aufwand). Lösungsidee: Nachfolger zufällig wählen
	\item Steilster An- oder Abstieg kann zu lokalem statt globalen Optimum führen. Lösungsidee: Unter Umständen auch "`schlechtere"' Lösungen im nächsten Iterationsschritt akzeptieren
\end{itemize}

\subsubsection{Grundalgorithmus}
\begin{minipage}{\textwidth}
\begin{lstlisting}[frame=single,numbers=left,mathescape]
Initialisiere $q$
#MARKER
Erzeuge $p$ aus $q$
Falls $(p,q)$ nicht akzeptabel {
	Springe zu #MARKER
}
Aktualisierungen $q \leftarrow p,...$
Falls Ende nicht erreicht {
	Springe zu #MARKER
}
Gebe $q$ aus
\end{lstlisting}
\end{minipage}

\subsubsection{Simuliertes Tempern}
\begin{itemize}
	\item Technik zur Züchtung von Kristallen (beim Härten von Stahl)
	\item Temperatur wird kontrolliert abgesenkt
	\item Dabei sinkt die Energie des Systems nicht monoton
\end{itemize}

\paragraph{Maximumsalgorithmus}
\textbf{Gegeben:} Temperaturen \(t_1,t_2,t_3,...\) und \(K\) als obere Schranke für die maximal zu berücksichtigenden Nachbarn
\\\\
Verschlechterungen werden akzeptiert, wenn die \textit{Aktzeptanzbedingung}
\[exp(\frac{c(p)-c(q)}{t_i}) > Zufallszahl \in \lbrack 0,1 \rbrack\]
gilt. Bei großen Temperaturen werden Verschlechterungen eher akzeptiert als bei kleinen (beispielsweise bei lokalen Maxima).
\\\\
\begin{minipage}{\textwidth}
\begin{lstlisting}[frame=single,numbers=left,mathescape]
#MARKER
k = 1
Repeate {
	Bestimme zufaelligen Nachfolger $p \in N(q)$
	$k++$
} until $k>K$ OR $c(p)>c(q)$ OR $exp(\frac{c(p)-c(q)}{t_i}) > Zufallszahl \in \lbrack 0,1 \rbrack$

if $k>K$ {
	stop
} else {
	senke Temperatur: $i++$
	Spring zu #MARKER
}
\end{lstlisting}
\end{minipage}

\subsubsection{Schwellwert-Algorithmus}
\begin{itemize}
	\item Verwendung der Akzeptanzbedingung \(c(p) > c(q) - \sigma\)
	\item Der Schwellwert \(\sigma \geq 0\) wird regelmäßig abgesenkt
	\item Anschaulich: \(\sigma\) erlaubt das kurzzeitige Abwärtsgehen nach einem lokalen Maximum. Mit fortschreitendem Aufstieg wird die Toleranz abwärts zu gehen geringer
	\item Keine Garantie, dass das globale Optimum erreicht wird
\end{itemize}

\subsubsection{Sintflut-Maximierung}
\begin{itemize}
	\item Es gibt eine untere Grenze \(F\), die nicht unterschritten werden darf
	\item \(F\) wird regelmäßig angehoben
	\item Akzeptanzbedingung \(c(p) \geq F\) ist unabhängig von \(q\)
	\item Keine Garantie, dass das globale Optimum erreicht wird
\end{itemize}

\subsubsection{Rekordjagd-Algorithmus}
\begin{itemize}
	\item Der bisher höchste Wert (Rekord) wird wird gespeichert
	\item Dieser darf nur um eine bestimmte Toleranz \(\delta\) unterschritten werden
	\item Der Rekord wird regelmäßig abgesenkt
	\item Die Akzeptanz \(c(p) \geq Rekord-\sigma\) ist unabhängig von \(q\)
	\item Keine Garantie, dass das globale Optimum erreicht wird
\end{itemize}

\subsubsection{Vergleich der Verfahren}
\begin{itemize}
	\item Beispiel Gröschels-Handlungsreisender: Bohre 442 Löcher in möglichst kurzer Zeit in eine Platine. Der Sintflut-Algorithmus bietet die beste Lösung (kommt der mathematisch besten Lösung am nächsten)
	\item \textbf{Feststellungen von Dueck, Scheuer und Wallmeister}
	\begin{itemize}
		\item Nur Schwellwert-Verfahren und simuliertes Tempern können aus kleinen, aber tiefen lokalen Minima entkommen
		\item Allerdings sind bei hoch-nicht-lineare Optimierungsaufgaben die Extremwerte im Allgemeinen weder markant noch tief
		\item Sintflut- und Schwellwert-Verfahren sind dem simulierten Tempern überlegen
		\item Der Sintflut-Algorithmus ist fast genauso gut wie das Schwellwert-Verfahren, nicht ganz so stabil in der Qualität der Lösungen, dafür jedoch ewas schneller
		\item Das Schwellwert-Verfahren ist die Methode der Wahl
		\item Bei einem reichhaltigen Sortiment von Veränderungsschritten wird besser optimiert
	\end{itemize}
\end{itemize}


\subsection{Evolutionäre Algorithmen}
\textbf{Idee:} Nachbilden des Evolutionsprinzips aus der Biologie.

\subsubsection{Einführung}
\begin{itemize}
	\item Eine \textit{Population} besteht aus \textit{Individuen}
	\item Ein \textit{Individuum} besitzt einen \textit{Genotyp} (Merkmalsvektor) \(q \in \mathbb{R}^n\) und einen \textit{Phänotyp} (Bewertung bzw. Fitness)
	\textit{Individuen} können sich fortpflanzen und ihren \textit{Genotyp} verändern (Mutation). Haben sie zwei oder mehr Eltern heißen sie \textit{Kreuzungen}, haben sie nur einen Eltern sind es \textit{Klone}
	\item Die Größe der \textit{Population} wird einigermaßen konstant gehalten, d.h. es werden immer wieder Lösungen verworfen ("`survival of the fittest"')
\end{itemize}

\subsubsection{Evolutionsstrategien}
\begin{itemize}
	\item Ein Individuum wird durch \(q \in \mathbb{R}^n\) und einen Streuungsvektor \(\sigma \in \mathbb{R}^n\) repräsentiert
	\item Nachkommen mutieren nach der Regel \(q^{(t+1)} = q^t+d\), wobei \(d\) zufällig normal- oder geometrisch verteilt ist mit Streuungsvektor \(\sigma\)
	\item \(\sigma\) kann bei der Evolution mitverändert werden
\end{itemize}

\subsubsection{Die Plus-Evolutionsstrategie}
\begin{itemize}
	\item Die Population \(Q\) ändert sich mit der Zeit \(t\), nicht aber ihre Größe \(\mu := |Q|\)
	\item Zu jedem Zeitpunkt werden \(\lambda\) Nachkommen erzeugt
	\item Die \(\mu\) Individuen mit der besten Fitness \(c(q)\) untern den \(\mu\) Eltern und \(\lambda\) Nachkommen bilden die nächste Polulation \(Q\). Die anderen \(\lambda\) Individuen sterben, Eltern können überleben
	\item Die Eltern aller Individuen werden gleichverteilt aus \(Q\) gewählt 
\end{itemize}

\subsubsection{Die Komma-Evolutionsstrategie}
\begin{itemize}
	\item Gleich der \textit{Plus-Strategie}, allerdings überleben die Eltern nicht
	\item Nur die Stärksten der Nachkommen überleben
\end{itemize}

\subsubsection{Mehrere Eltern}
\begin{itemize}
	\item Individuen können auch mehrere Eltern haben
	\item \textbf{Methoden}
	\begin{itemize}
		\item Mischen: Für jedes Merkmal wird zufällig ein Elternteil bestimmt, von dem es übernommen wird
		\item Mitteln: Für jedes Merkmal wird der Durchschnittswert der Eltern gebildet
	\end{itemize}
\end{itemize}


\subsection{Genetische Algorithmen}

\subsubsection{Prinzip}
\begin{itemize}
	\item Binäre Merkmalsvektoren, d.h. \(Q = \{0,1\}^n\)
	\item In jeder Generation erzeugen \(\mu\) Eltern \(\mu\) Nachkommen und nur diese überleben
	\item Starke Eltern paaren sich "`häufiger"' (höhere Wahrscheinlichkeit) als "`schwächere"'
\end{itemize}

\subsubsection{Ablauf}
\begin{enumerate}
	\item \textbf{Fortpflanzung}
	\begin{itemize}
		\item Jedes Individuum \(q\) wird mit der Wahrscheinlichkeit \(W(q) = \frac{c(q)}{\sum_{p \in Q}c(p)}\) Elter
		\item Die \(\mu\) Individuen erzeugen \(\mu\) Klon-Nachkommen. Nur diese überleben
	\end{itemize}
	\item \textbf{Kreuzung}
	\begin{itemize}
		\item Dann werden unter den \(\mu\) Nachkommen \(p\%\) Individuen ausgesucht, die der Kreuzung interzogen werden
		\item Die Kreuzungspartner werden zufällig festgelegt
		\item Kreuzung per Kreuzprodukt
	\end{itemize}
	\item \textbf{Mutation:} Jedes Bit des Merkmalvektors wird mit einer sehr kleinen Mutationswahrscheinlichkeit \(p_m\) invertiert
\end{enumerate}


\subsection{Vergleich}

\subsubsection{Evolutionsstrategien}
\begin{itemize}
	\item konvergieren im Allgemeinen schneller
	\item enden öfter in lokalem Minimum
\end{itemize}

\subsubsection{Genetische Algorithmen}
\begin{itemize}
	\item bevorzugen Kreuzungen vor Mutationen
	\item spähen daher Suchraum in größeren Sprüngen aus
	\item und finden öfter ein globales Optimum
	\item konvergieren aber schlechter
\end{itemize}


\subsection{Partikel-Schwarm-Optimierung}
\textbf{Idee:} Übertragen des Verhaltens von Fisch- und Vogelschwärmen auf allgemeine Optimierung.

\subsubsection{Einführung}
Ein Schwarm besteht aus Partikeln. Zum \(i-\)ten Partikel gehören seine
\begin{itemize}
	\item Position \(p_i(t)\) im \(\mathbb{R}^n\) abhängig von der Zeit \(t\)
	\item Fitness \(f(p_i)\)
	\item Geschwindigkeit \(v_t(t) = p_t(t)-p_i(t-1)\)
\end{itemize}
Dabei ist \(f(x)\) zu optimieren.

\subsubsection{Algorithmenskizze}
\begin{itemize}
	\item Initialisiere die \(p_t(0)\) und \(v_i(0)\) zufällig
	\item Aktualisiere die nächsten Positionen, Geschwindigkeiten und Lernkonstanten
	\item Typische Werte: ca 20-40 Partikel
\end{itemize}

\subsubsection{Superschwarm-Optimierung}
\begin{itemize}
	\item Die Lernkonstanten können mit einem Superschwarm optimiert werden
	\item Die Position eines Superpartikels entspricht einer Parameterwahl und der Position eines einfachen Schwarms mit diesen Parametern
	\item Die Fitness der optimalen Fitness, die durch eine Partikelschwarm-Optimierung mit dieser parameterwahl erzielt wird
\end{itemize}


\subsection{Ameisen-Systeme}
\begin{itemize}
	\item Ameisen markieren ihre Wege mit Duftstoffen (Pheremonen)
	\item Kurze Wege zu Futterplätzen werden in der gleichen Zeit öfter markiert als lange
	\item Geleitet durch die Intensität der Markierung finden Ameisen die kürzesten Wege
\end{itemize}
Dies kann auf Probleme übertragen werden, in denen Pfade in Grapen zu bestimmen sind.

\subsubsection{Beispiel Rundreise}
Seien
\begin{itemize}
	\item \(\{1,...,n\}^2\) die Kantenmenge eines Graphen
	\item \(d_{ij}\) die Länge der Kante \(ij\)
	\item \(p_{ij}\) die Intensität der Pheromonmarkierung
\end{itemize}
Von \(m\) Knoten aus wird je eine Ameise auf eine Rundreise geschickt. Danach werden die \(p_{ij}\) mit der Evaporationsrate \(\rho \in \lbrack 0,1)\) neu gesetzt:
\[p_{ij} = \rho \cdot p_{ij} + \sum_k \Delta p_{ij}^k\]
\[\Delta p_{ij}^k = \begin{cases} \frac{1}{d_{ij}}, & falls~Ameise~k~Kante~ij~benutze \\ 0, & sonst \end{cases}\]
Danach suchen die Ameisen wiederholt erneut eine Rundreise, bis eine Abbruchbedingung erfüllt ist.



\section{Der De-Casteljau-Algorithmus}
Mit Unterteilungsalgorithmen lassen sich Kurven und Flächen beliebiger Gestalt erzeugen. In der Regel wird ein initiales Polygon wiederholt verfeinert und geglättet, so dass eine konvergente Polgonenfolge entsteht.

\subsection{Der Algorithmus}
\textbf{Idee:} Eine Bézierkurve kann geteilt und durch zwei aneinandergesetzte Bézierkurven dargestellt werden. Dies wird rekursiv fortgesetzt.\footnote{\url{http://de.wikipedia.org/wiki/De-Casteljau-Algorithmus}}

Der Algorithmus besteht daher mit der Eingabe
\[b_0^0,...b_n^0 \subset \mathbb{R}^d\]
aus einfachen Interpolationsschritten:
\\\\
\begin{minipage}{\textwidth}
DECASTELJAU
\begin{lstlisting}[frame=single,numbers=left,mathescape]
Fuer $k = 1,...,n$ {
	Fuer $i = 0,...,n-k$ {
		$b_i^k = b_i^{k-1} \cdot (1-t) + b_{i+1}^{k-1}\cdot t$ 
	}
}
\end{lstlisting}
\end{minipage}


\subsection{Kanonische Parametrisierung}
Die durch den Unterteilungsoperator \(C*\) erzeugten Polygone
\[B^k := B_0^k,...,B_{2^k-1}^k\]
konvergieren gegen eine polynomielle Kurve. Um dies zu zeigen, parametrisiert man die Polygone und betrachtet ihre Ableitungen.


\subsection{Differenzenpolygone}
Sei \(B\) das Polygon \(b_0,...,b_n\). Sein \textit{Differenzenpolygon} ist das Polygon
\[\Delta B := \Delta b_0,...,b_n\]
\[\Delta B := \Delta(b_0,...,b_n)\]
\[\Delta B := (\Delta b_0),...,(\Delta b_{n-1})\]
\[\Delta B := (b_1-b_0),...,(b_n-b_{n-1})\]

Für \(B_0\cdot B_1 := C*\cdot(B,1\) gilt
\[\Delta B_0\cdot \Delta B_1 = \frac{1}{2}\cdot C* \cdot(\Delta B,1).\]
Die Differenzen eines unterteilten Polygons lassen sich also aus den halbierten Differenzen des ursprünglichen Polygone mit Hilfe des de-Casteljau-Algorithmus berechnen.


\subsection{Ableitung unterteilter Polygone}
Unterteilen wir ein Polygon \(B\) mit \(n\) Kanten \(k\)-mal mit dem de-Casteljau-Algorithmus, erhalten wir die stückweise lineare Funktion
\[b(t) := L_K(B).\]
Wir bezeichnen ihre Knoten mit
\[\beta_i^{k,j} := \frac{jn+i}{n\cdot 2^k}\]
und ihre Werte in den Knoten mit
\[b_i^{k,j} := b^k(\beta_i^{k,j}).\]
Die Ableitung
\[b(t) := \frac{d}{dt}~b(t)\]
ist stückweise konstant. Die Parametrisierung des Differenzenpolygons ist stückweise konstants und kann abgeschätzt werden:
\[sup(\lbrack0,1\rbrack)~|~\dot{b}^k(t)-n\cdot L_k(\Delta B)~|~\in \mathcal{O}(\frac{1}{2^k}\]




\section{Der Algorithmus von Lane und Riesenfeld}
Lane und Riesenfeld veröffentlichten 1980 einen Unterteilungsalgorithmus um stückweise polynomielle Kurven (Splines) zu erzeugen. Dabei handelt es sich um einen stationären Unterteilungsalgorithmus, der durch eine einzige, wiederholt anzuwendende lineare Operation beschreibar ist.

\subsection{Der Algorithmus}
Der Algorithmus erzeugt eine Folge von Polygone (Kontrollpolygone), die den Grenzwert der Folge, die Limeskurve, definieren und deren Form beeinflussen
\[c_{\mathbb{Z}} := (c_i)_{i \in \mathbb{Z}}\]
\[= (...,c_{-1},c_0,c_1,...)\]
Endliche Polygone können als biinfinite aufgefasst werden, bei denen nur endlich viele der Kontrollpunkte \(c_i\) von \(0\) verschieden sind.
\\\\
\textbf{Eingabe:} \(c_{\mathbb{Z}}^0 \subset \mathbb{R}^d\) ein Polygon, \(n \in \mathbb{N}_0\) der Grad, \(m \in \mathbb{N}_0\) die Unterteilungstiefe
\\\\
\begin{minipage}{\textwidth}
LANE-RIESENFELD
\begin{lstlisting}[frame=single,numbers=left,mathescape]
Fuer $k = 1,...,m$ {

	// verdopple
	Fuer $i \in \mathbb{Z}$ {
		$d_{2i}^0 = d_{2i+1}^0 = c_i^{k-1}$
	}

	// Mittele
	Fuer $j = 1,...,n$ {
		Fuer $i \in \mathbb{Z}$ {
			$d_i^j = \frac{1}{2} \cdot (d_{i-1}^{j-1}+d_i^{j-1})$ 
		}
	}

	// benenne um
	Fuer $i \in \mathbb{Z}$ {
		$c_i^k = d_i^n$
	}
}
\end{lstlisting}
\end{minipage}


\subsection{Unterteilungsmatrizen}
Zur Analyse des LR-Algorithmus können die Koordinaten der Kontrollpolygone betrachtet werden. Es reicht somit ein skalarwertiges Polygon
\[c := \begin{bmatrix} \vdots \\ c_{-1} \\ c_0 \\ c_1 \\ \vdots \end{bmatrix} \in \mathbb{R}^{\mathbb{Z}}\]
zu unterteilen.
Die Unterteilungsmatrizen \(U_n, n \in \mathbb{N}_0\) stellen den LR-Algorithmus dar und können durch \(n\)-fache Mittelung der Spalten einer biinfiniten Matrix \(D\) berechnet werden. Man erhält so
\[U_1 = \frac{1}{2}
\begin{bmatrix}
	\ddots 	& 1 			& 				& 			\\
			& 2 			& 				& 			\\
			& 1 			& 1 			& 			\\
			& 				& 2 			& 			\\
			& 				& 1 			& \ddots 	\\
\end{bmatrix},
\]
\[U_2 = \frac{1}{4}
\begin{bmatrix}
	\ddots 	& 1 			& 				&			\\
			& 3 			& 				&			\\
			& 3 			& 1 			&			\\
			& 1 			& 3 			&			\\
			& 				& 3 			&			\\
			& 				& 1 			& \ddots 	\\
\end{bmatrix},
\]
und allgemein
\[U_n :=
\begin{bmatrix}
	\ddots 	& \vdots 		&				&			\\
			& \alpha_0		&				&			\\
			& \alpha_1		& \vdots		&			\\
			& \alpha_2		& \alpha_0		&			\\
			& \vdots		& \vdots		&			\\
			& \alpha_{n+1}	& \alpha_{n-1} 	&			\\
			& \vdots		& \alpha_n		&			\\
			&				& \alpha_{n+1}	&			\\
			&				& \vdots		& \ddots 	\\
\end{bmatrix},
\]
wobei
\[\alpha_i = \begin{cases} \frac{1}{2^n}, & falls~i=0,...,n \\ 0, & sonst \end{cases}\]
die mit \(2^{-n}\) skalierten Binomialkoeffizienten sind.

Die Zeilen der Matrix \(u_n\) enthalten alternierend die \(\alpha_i\) mit geraden und ungeraden Indexen.

Die Unterteilung
\[b:= \begin{bmatrix} \vdots \\ b_i \\ \vdots \end{bmatrix} := U_n \begin{bmatrix} \vdots \\ c_k \\ \vdots \end{bmatrix}\]
des Polygons \(c\) berechnet sich daher nach den beiden Regeln
\[b_{2i} = \sum_{k\in \mathbb{Z}} \alpha_{2i-2k}\cdot c_k\]
und
\[b_{2i+1} = \sum_{k\in \mathbb{Z}} \alpha_{2i+1-2k}\cdot c_k,\]
die zur \textit{Unterteilungsgleichung}
\[b_i = \sum_{k\in \mathbb{Z}} \alpha_{i-2k}\cdot c_k, i \in \mathbb{Z}\]
zusammengefasst werden können.


\subsection{Das Symbol}
Die Unterteilungsgleichung kann als Polynommultiplikation aufgefasst werde. Dazu werden die Folge \(b_{\mathbb{Z}}\), \(\alpha_{\mathbb{Z}}\) und \(c_{\mathbb{Z}}\) als symbolische Polygone
\[b(z) := \sum_{i \in \mathbb{Z}} b_i \cdot z^i,\]
\[\alpha(z) := \sum_{i \in \mathbb{Z}} \alpha_i \cdot z^i,\]
\[c(z) := \sum_{i \in \mathbb{Z}} c_i \cdot z^i,\]
dargestellt. Multipliziert man \(\alpha(z)\) und \(c(z^2)\) symbolisch, so erhält man
\[\alpha(z) \cdot c(z^2) = \sum_j \alpha_j\cdot z^j \cdot \sum_k c_k\cdot z^{2k} = b(z),\]
die Laurent-Polynome des unterteilten Polynoms. Daher hat die Unterteilungsgleichung die Form
\[\beta(z) = \alpha(z)\cdot c(z^2).\]
Das Polynom \(\alpha(z)\) stellt den LR-Algorithmus dar und kann gegen ein beliebiges anderes ersetzt werden, um einen anderen Unterteilungsalgorithmus zu erhalten. Es heißt das \textit{Symbol} des Unterteilungsalgorithmus.

\subsubsection{Begrifflichkeiten}
\begin{itemize}
	\item Das Symbol des Unterteilungsalgorithmus heißt \textit{stationäre}, weil immer wieder der selbe Unterteilungsoperator angewendet wird
	\item Der Unterteilungsoperator heißt \textit{linear}, weil er durch eine Matrix dargestellt werden kann
\end{itemize}

\subsubsection{Symbol des LR-Algorithmus}
\[\alpha_n(z) = \frac{1}{2^n} \sum_{i=0}^{n+1} \binom{n+1}{i} \cdot z^i = \frac{1}{2^n}\cdot (1+z)^{n+1}\]


\subsection{Das Differenzenschema}
Neben dem Vorwärtsdifferenzenoperator \(\Delta\) gibt es den Rückwärtsdifferenzenoperator \(\nabla\), der eim Polygon \(c:=(c_i)_{i \in \mathbb{Z}}\) auf das Differenzenpolygon
\[\nabla c := (\nabla c_i)_{i \in \mathbb{Z}}\]
der Rückwärtsdifferenzen
\[\nabla c_i := c_i - c_{i-1}\]
abbildet. Er unterscheidet sich bis auf eine Indexverschiebung nicht vom Vortwärtsdifferenzenoperator.

Unterteilt man ein Polygon \(c\) gemäß der Unterteilungsgleichung
\[b(z) = \alpha(z) \cdot c(z^2)\]
genügen die Differenzenpolygone \(b_{\nabla}(z) = \frac{\alpha(z)}{1+z} \cdot c_{\nabla}(z^2)\) und \(c_{\nabla}(z) = (1-z)\cdot c(z)\) der Unterteilungsgleichung
\[b_{\nabla}(z) = \beta(z) \cdot c_{\nabla}(z^2),\]
wobei \(\beta(z) = \frac{\alpha(z)}{1+z}\). \(\beta(z)\) das Differenzenschema zu \(\alpha(z)\) bezeichnet.


\subsection{Uniforme Parametrisierung}
Um zu zeigen, dass eine Polygonfolge gegen eine Kurve oder Funktion konvergiert, parametrisiert man die durch den LR-Algorithmus erzeugten Polygone.

Sei \(c := \lbrack ...,c_{-1},c_0,c_1,...\rbrack^T\) ein skalierwertiges Polygon und sei \(d := \lbrack ...,d_{-1},d_0,d_1,...\rbrack^T\) dessen Differenzenpolygon.

Nach \(k\)-maliger Unterteilung mit dem LR-Algorithmus ergeben sich die Polygone
\[c^k := \begin{bmatrix} u_i^k \\ c_i^k \end{bmatrix}, i \in \mathbb{Z}\]
und
\[d^k := \begin{bmatrix} v_i^k \\ d_i^k \end{bmatrix}, i \in \mathbb{Z}.\]
Wir fassen die Polygone \(c^k\) und \(d^k = \nabla c^k\) als stückweise lineare Funktionen \(c^k(x)\) und \(d^k(x)\) mit den Knoten \(u_i^k\), bzw. \(v_i^k\) auf, so dass
\[c^k(u_i^k) = c_i^k\]
und
\[d^k(v_i^k) = d_i^k.\]

\subsubsection{Folgerung 1}
Die Ableitung \(\frac{d}{dx}c^k(x)\) ist eine stückweise konstante Funktion, für die über \((u_{i-1}^k, u_i^k)\)
\[\frac{d}{dx}c(x) = \frac{\nabla c_i^k}{\nabla u_i^k} = 2^k d_i^k\]
gilt.

\subsubsection{Folgerung 2}
Die stückweise lineare Funktion \(2^k d^k(x)\) approximiert die Ableitung \(\frac{d}{dx} c^k(x)\) und es gilt
\[sup(x \in \mathbb{R})~|~\frac{d}{dx} c^k(x) - 2^k d^k(x)~| \in \mathcal{O}(2^{-k}).\]


\subsection{Konvergenz}
Die Funktion \(c^k(x)\) konvergiert gegen eine Funktion \(c_{\infty}(x)\) so, dass
\[sup(x \in \mathbb{R})~|~c_{\infty}(x) - c^k(x)~|~\in \mathcal{O}(4^{-k}).\]

\subsubsection{Folgerung 1}
Die skalierten Differenzpolygone \(2^k d^k(x)\) (Ableitungspolygone) konvergieren gegen
\[\frac{d}{dx} c_{\infty}(x).\]

\subsubsection{Folgerung 2}
Induktiv folgt aus \textit{Folgerung 1}, dass die \(n\)-te Ableitung
\[\frac{d^n}{dx^n} c_{\infty}(x)\]
der Limesfunktion stückweise konstant ist.



\section{Unterteilungsalgorithmen für Flächen}

\subsection{Tensorprodukt}
Ein regelmäßiges biinfinites Kontrollnetz kann durch eine biinfinite Matrix
\[C = c_{\mathbb{Z}^2}\]
beschrieben werden. Die Matrizen \(U\) und \(V\) zweier stationärer Unterteilungsalgorithmen für Kurven (z.B. der Lane-Riesenfeld-Algorithmus) bilden das Kontrollnetz
\[B := b_{\mathbb{Z}^2} := UCV^T,\]
in dem alle Spalten von \(C\) mit \(U\) und dann alle Zeilen von \(UC\) mit \(V\) unterteilt werden. Das Paar \((U,V)\) heißt \textit{Tensorproduktunterteilungsschema} oder kurz \textit{Tepus}.

Die Netze \(U^kC(V^T)^k\) konvergieren gegen eine Fläche, wenn \(U\) und \(V\) konvergente Kurvenunterteilungsalgorithmen sind.


\subsection{Symbole}
Die Matrix \(C=c_{\mathbb{Z}^2}\) hat das Symbol
\[c(x) = \sum_{i \in \mathbb{Z}^2} c_i x^i.\]
Sind \(U\) und \(V\) stationäre Unterteilungsalgorithmen für Kurven mit den Symbolen \(\alpha(x)\) und \(\beta(x)\), hat das unterteilte Netz
\[B := b_{\mathbb{Z}^2} := UCV^T\]
das Symbol
\[b(x,y) := \alpha(x) \cdot c(x^2,y^2) \cdot \beta(y).\]
Das Produkt
\[\gamma(x,y) := \alpha(x) \cdot \beta(y)\]
ist das \textit{Symbol des Tepus} \((U,V)\) und die Unterteilungsgleichung ist
\[b(x) = \gamma(x) \cdot c(x^2).\]
Multipliziert man die Unterteilungsgleichung aus, erhält sie die Form
\[b_i = \sum_{j \in \mathbb{Z}^2} \gamma_{i-2j} \cdot c_j.\]


\subsection{Masken}
Sei \(\Gamma := \gamma_{\mathbb{Z}^2}\) eine biinfinite Matrix und sei
\[\gamma(x,y) := \lbrack ...,x^{-1},x^0,x^1,...\rbrack \cdot \Gamma \cdot \begin{bmatrix} \vdots \\ y^{-1} \\ y^0 \\ y^1 \\ \vdots \end{bmatrix}\]
das Symbol eines Unterteilungsalgorithmus. Die Teilmatrizen
\[\Gamma_i := \lbrack \gamma_{i-2j} \rbrack_{j \in \mathbb{Z}^2}\]
für \(i=(0,0),~(1,0),~(0,1),~(1,1)\) heißen \textit{Masken}. Sie werden graphisch dargestellt, indem die \(\gamma_{i-2j} \ne 0\) an die Punkte eines Teilnetzes geschrieben werden, mt denen sie multipliziert werden. Der resultierende, gewichtete Punkt wird durch einem ausgefüllten, schwarzen Punkt gekennzeichnet.

\subsubsection{Beispiel: Mittelungsoperator}
Der Mittelungsoperator \((M,M)\) mit dem Symbol
\[\mu(x,y)= \frac{1}{4}(1+x)(1+y)\]
hat nur eine Maske und interpoliert den Mittelpunkt aus vier Eckpunkten. Die zugehörige Unterteilungsgleichung ist
\[b(x) = \mu(x) \cdot c(x).\]
Die Maske des Mittelungsoperators kann für beliebige Netze und beliebige geometrische Figuren verfeinert werden.


\subsection{Konvergenz}
Wenn sich die Gewichte jeder Maske eines Unterteilungsalgorithmus für regelmäßige Vierecksnetzezu \(1\) summieren und die maximale Kantenlänge \(k\)-mal unterteilter Netze für \(k \rightarrow \infty\) gegen \(0\) geht, konvergieren die Netze gegen eine stetige Fläche.

Unterteilungsalgorithmen für regelmäßige Dreiecksnetze können als Unterteilungsalgorithmen für regelmäßige Vierecksnetze aufgefasst werden.



\section{Textsuche}
Im Folgenden bezeichnet \(A\) ein Alphabet, \(t = t_1,...,t_n \in A^n\) einen Text und \(s = s_1,...s_m \in A^m\) einen Suchtext, für den bestimmt werden soll, ob er in \(t\) und gegebenenfalls an welcher Stelle er auftritt. Es wird vorausgesetzt, dass \(m < n\).

\subsection{Naive Suche}
\begin{minipage}{\textwidth}
NAIVE-SUCHE
\begin{lstlisting}[frame=single,numbers=left,mathescape]
i = 0
While $i \leq n-m$ {
	j = m
	While $j > 0$ and $s_j = t_{i+j}$ {
		j--
	}
	Falls $j == 0$ {
		Return i
	} sonst {
		i++
	}
}
\end{lstlisting}
\end{minipage}
Der Aufwand für diesen Algorithmus liegt im schlechtesten Fall in \(\Theta(m\cdot n)\).


\subsection{Die Vorkommensheuristik (Bad-Character-Heuristik)}
Im Algorithmus \textit{NAIVE-SUCHE} wird \(i\) um jeweils \(1\) erhöht, d.h. der Suchtext wird verschoben. Man kann \(i\) oft um mehr als \(1\) erhöhen, wenn man für jedes Zeichen \(a \in A\) weiß, an welcher Stelle \(\nu\) es in \(s\) vorkommt. Dies wird durch die \textit{Vorkommensfunktion} beschrieben:
\[\nu \rightarrow \{0,...,m\}\]
\[a \mapsto \nu(a),\]
wobei
\[\nu(a) := min\{k~|~a \notin s_{k+1},...,s_m~und~(a=s_k \lor k=0)\}\]

\subsubsection{Vorgehen anschaulich}
Die Beschreibung entstammt der deutschen Wikipedia\footnote{\url{http://de.wikipedia.org/wiki/Boyer-Moore-Algorithmus}}.
\begin{itemize}
	\item Muster wird linksbündig unter den Text geschrieben und von rechts nach links mit dem Text verglichen
	\item Sobald ein Mismatch auftritt, wird berechnet wie weit das Suchmuster nach rechts verschoben werden kann
	\item Existiert der entsprechende Buchstabe nicht im Muster, kann um die ganze Länge des Musters verschoben werden
\end{itemize}
Die Funktion \(\nu\) kann mit einem Aufwand in \(\mathcal{O}(|A|+m)\) vorberechnet werden.


\subsection{Die Suffix-Heuristik (Good-Suffix-Heuristik)}
Mit einer zweiten Heuristik lässt sich die Laufzeit der Naiven Suche noch weiter reduzieren, so dass sie in \(\mathcal{O}(n+m)\) liegt.

\subsubsection{Vorgehen anschaulich}
Stimmt beim Vergleich des Musters mit dem Text von rechts nach links ein Suffix des Musters mit dem Text überein und tritt danach aber ein Mismatch auf, wird das Muster soweit nach rechts geschoben, bis ein Teilwort des Musters wieder auf das Suffix passt. Existiert das Suffix kein zweites Mal im Muster, wird das Muster um seine volle Länge nach rechts verschoben\footnote{\url{http://de.wikipedia.org/wiki/Boyer-Moore-Algorithmus}}.


\subsection{Der Algorithmus von Boyer und Moore}
Der Algorithmus von Boyer und Moore erweitert die Naive Suche um die Vorkommens- und Suffixheuristiken.
\\\\
Um das Vorgehen effizient zu gestalten, wird für beide Heuristiken in einem Vorverarbeitungsschritt jeweils eine Sprungtabelle errechnet. Die Sprungtabelle für die Bad-Character-Heuristik enthält für jedes im Suchmuster vorkommende Zeichen den Abstand von der Position des letzten Vorkommens im Suchmuster bis zum Ende des Suchmusters. Die Tabelle für die Good-Suffix-Heuristik enthält für jedes Teilmuster (von hinten aus gesehen) den Abstand vom Ende des Musters, ab dem es wieder im Muster vorkommt.\footnote{\url{http://de.wikipedia.org/wiki/Boyer-Moore-Algorithmus}}

\begin{minipage}{\textwidth}
BOYER-MOORE
\begin{lstlisting}[frame=single,numbers=left,mathescape]
i = 0
While $i \leq n-m$ {
	j = m
	While $j > 0$ and $s_j = t_{i+j}$ {
		j--
	}
	Falls $j == 0$ {
		Return i
	} sonst {
		$\nu = \nu(t_{i+j})$
		Falls $\nu < j$ {
			$i = i+max \{j-v,\sigma(j)\}$
		} sonst {
			$i = i + max\{m-\nu+1,\sigma(j)\}$
		}
	}
}
\end{lstlisting}
\end{minipage}
In der Praxis trägt die Suffixheuristik kaum zu Beschleunigung bei. Sie verhindert lediglich eine worst-case-Laufzeit in \(\Theta(m\cdot n)\).


\subsection{Berechnung der Suffixvorkommensfunktion}

\subsubsection{Definition Präsuffix}
Ein Präfix eines Wortes \(w\), das zugleich ein Suffix von \(w\) ist, nennen wir Präsuffix von \(w\) und das größte echte Präsuffix \(geps(w)\).
\\\\
Sei \(w_j := s_{j+1},...,s_m\) und
\[\gamma(j) := |gpes(w_j|.\]
Die \(gpes\)-Länge ist für \(j=0,...,m-1\) definiert. Insbesondere ist \(\gamma(m-1)=0\).

Mit Hilfe von \(\gamma\) lässt sich die Funktion \(\sigma\) so darstellen:
\[\sigma(j) = min\Big( \{k\in \{1,...,j\} ~|~\gamma(j-k) = m-j\} \cup \{m-\gamma(0)\}\Big).\]
Aus
\[\gamma(j-k) = m-j\]
folgt mit \(i := j-k\)
\[j = m-\gamma(i)~und\]
\[k = m-\gamma(i)-1.\]

\subsubsection{Berechnung von \(\sigma\)}
\begin{itemize}
	\item Eingabe: \(\gamma(0,...,m)\)
	\item Ausgabe: \(\sigma(1,...,m)\)
\end{itemize}

\begin{minipage}{\textwidth}
\(\sigma\)
\begin{lstlisting}[frame=single,numbers=left,mathescape]
For $j=1,...,m$ {
	$\sigma = m-\gamma(0)$
}
For $i = 0,...,m-1$ {
	$k = m-\gamma(i)-1$
	$j = m-\gamma(i)$

	Falls $\sigma(j) > k$ {
		$\sigma(j) = k$
	}
}
\end{lstlisting}
\end{minipage}
It \(\gamma\) bekannt, ist die Laufzeit von \(\sigma\) linear in \(m\).

\subsubsection{Berechnung von \(\gamma\)}
\(gpes(w_{i-1})\) verkürzt um \(s_i\) ist ebenfalls Präsuffix von \(w_i\), daher gilt
\[\gamma(i-1) -1 \leq \gamma(i).\]
Falls \(j := m-\gamma(i)\) und \(s_i \ne s_j\), ist \(geps(w_{i-1})\) verkürzt um \(s_i\) auch Präsuffix von \(w_j\). Daraus folgt der Algorithmus:
\begin{itemize}
	\item Eingabe: \(s_1,...,s_m\)
	\item Ausgabe: \(\gamma(0,...,m-1)\)
\end{itemize}

\begin{minipage}{\textwidth}
\(\gamma\)
\begin{lstlisting}[frame=single,numbers=left,mathescape]
$\gamma(m-1) = 0$
For $i=m-1,...,1$ {
	$j = m-\gamma(i)$
	While $s_i \ne s_j$ und $\gamma(j) > 0$ {
		$j = m-\gamma(j)$
	}

	Falls $s_i == s_j$ {
		$\gamma(j-1) = \gamma(j) + 1$
	} sonst {
		$\gamma(i-1) = 0$
	}
}
\end{lstlisting}
\end{minipage}

\subsubsection{Aufwand von \(\gamma\)}
Der Aufwand für \(\gamma\) liegt in \(\mathcal{O}(m)\), denn
\begin{itemize}
	\item \(j\) wird in Zeile \(5\) erhöht
	\item und in Zeile \(3\) wegen Zeile \(9\) jeweils um \(1\) größer.
\end{itemize}
Da \(j\) anfangs \(m\) ist und immer \(\leq m\) ist, wird \(j\) höchstens \((m-1)\)-mal in Schritt \(5\) erhöht.

